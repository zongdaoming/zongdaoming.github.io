<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="multimodal neural translation tutorial, DorMin">
    <meta name="description" content="

聊天机器人的实现
作者: Matthew Inkawhich
译者: 宗道明



上个学期仔细看了一篇神经对话模型的Pytorch实现，踩了一些小坑，现记录如下。通过本教程，你可以快速实现一个聊天机器人并掌握Pytorch的一些入门技">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>multimodal neural translation tutorial | DorMin</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">DorMin</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">DorMin</div>
        <div class="logo-desc">
            
            无名逆流
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/zongdaoming/zongdaoming.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/zongdaoming/zongdaoming.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>





<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/14.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        multimodal neural translation tutorial
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }
</style>
<div class="row">
    <div class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/ML/" target="_blank">
                                <span class="chip bg-color">ML</span>
                            </a>
                        
                            <a href="/tags/multimodal-leanring/" target="_blank">
                                <span class="chip bg-color">multimodal leanring</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/ML/" class="post-category" target="_blank">
                                ML
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-09-09
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                        10.5k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        49 分
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <!-- # 多模态神经翻译 --导论（01）
---

## 多模态学习的研究方向 
模态可以简单理解为文字信息，视觉信息（文字和视频）和听觉信息（语音）。其主要研究方向可分为四点：
* **多模态表示学习**：主要研究如何将多个模态数据所蕴含的语义信息数值化为实值向量。
* **模态间映射** 主要研究如何将某一特定模态数据中的信息映射至另一模态。
* **对齐** 主要研究如何识别不同模态之间的部件、元素的对应关系。
* **融合** 主要研究如何整合不同模态间的模型与特征。
* **协同学习** 主要研究如何将信息富集的模态上学习的知识迁移到信息匮乏的模态，使各个模态的学习互相辅助。典型的方法包括多模态的零样本学习、领域自适应等。
### -->

<h1 id="聊天机器人的实现"><a href="#聊天机器人的实现" class="headerlink" title="聊天机器人的实现"></a>聊天机器人的实现</h1><blockquote>
<p><strong>作者</strong>: <a href="https://github.com/MatthewInkawhich" target="_blank" rel="noopener">Matthew Inkawhich</a></p>
<p>译者: <a href="https://github.com/zongdaoming" target="_blank" rel="noopener">宗道明</a></p>
</blockquote>
<!-- 在本教程中，我们探索了一个好玩和有趣的循环序列到序列的模型用例。我们将用 [Cornell Movie-Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html) 处的电影剧本来训练一个简单的聊天机器人。

在人工智能研究领域中对话模型是一个非常热门的话题。聊天机器人可以在各种设置中找到，包括客户服务应用和在线帮助。这些机器人通常由基于检索的模型提供支持，这些输出是某些形式问题预先定义的响应。在像公司IT服务台这样高度受限制的领域中，这些模型可能足够了，但是，对于更一般的用例它们不够健壮。教一台机器与多领域的人进行有意义的对话是一个远未解决的研究问题。最近，深度学习热潮已经允许强大的生成模型，如谷歌的神经对话模型[Neural Conversational Model](https://arxiv.org/abs/1506.05869)，这标志着向多领域生成对话模型迈出了一大步。 在本教程中，我们将在PyTorch中实现这种模型。 -->

<p>上个学期仔细看了一篇<strong>神经对话模型</strong>的Pytorch实现，踩了一些小坑，现记录如下。通过本教程，你可以快速实现一个聊天机器人并掌握Pytorch的一些入门技巧。可在谷歌提供的 <a href="https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/chatbot_tutorial.ipynb" target="_blank" rel="noopener">Google Colab</a> 训练此模型。</p>
<p><img src="img/encdec.jpg" alt="bot"></p>
<pre class=" language-py"><code class="language-py">> hello?
Bot: hello .
> where am I?
Bot: you re in a hospital .
> who are you?
Bot: i m a lawyer .
> how are you doing?
Bot: i m fine .
> are you my friend?
Bot: no .
> you're under arrest
Bot: i m trying to help you !
> i'm just kidding
Bot: i m sorry .
> where are you from?
Bot: san francisco .
> it's time for me to leave
Bot: i know .
> goodbye
Bot: goodbye .
</code></pre>
<p><strong>Highlights</strong></p>
<ul>
<li>数据集的加载和预处理 (这是一段标准的NLP处理程序)</li>
<li>用 <a href="https://arxiv.org/abs/1508.04025" target="_blank" rel="noopener">Luong attention mechanism(s)</a> 实现一个sequence-to-sequence模型</li>
<li>使用小批量数据联合训练解码器和编码器模型</li>
<li>实现贪婪搜索解码模块</li>
<li>学习Pytorch的基础技巧</li>
</ul>
<p><strong>鸣谢</strong></p>
<p>本教程借鉴以下源码：</p>
<ol>
<li>Yuan-Kuei Wu’s pytorch-chatbot implementation: <a href="https://github.com/ywk991112/pytorch-chatbot" target="_blank" rel="noopener">https://github.com/ywk991112/pytorch-chatbot</a></li>
<li>Sean Robertson’s practical-pytorch seq2seq-translation example: <a href="https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation" target="_blank" rel="noopener">https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation</a></li>
<li>FloydHub’s Cornell Movie Corpus preprocessing code: <a href="https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus" target="_blank" rel="noopener">https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus</a></li>
</ol>
<h2 id="Preparations"><a href="#Preparations" class="headerlink" title="Preparations"></a>Preparations</h2><p>首先，下载数据文件 <a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html" target="_blank" rel="noopener">Cornell Movie-Dialogs Corpus</a> 并将其放入当前目录下的<code>data/</code>文件夹下。之后，让我们引入一些必须的包。</p>
<pre class=" language-py"><code class="language-py">from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import torch
from torch.jit import script, trace
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
import csv
import random
import re
import os
import unicodedata
import codecs
from io import open
import itertools
import math

USE_CUDA = torch.cuda.is_available()
device = torch.device("cuda" if USE_CUDA else "cpu")
# specify gpu 
# os.environ["CUDA_VISIBLE_DEVICES"]="0,..."</code></pre>
<h2 id="下载和预处理数据"><a href="#下载和预处理数据" class="headerlink" title="下载和预处理数据"></a>下载和预处理数据</h2><p><a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html" target="_blank" rel="noopener">Cornell Movie-Dialogs Corpus</a>[size=9.5M] 是一个丰富的电影角色对话数据集：</p>
<ul>
<li>10,292 对电影角色的220,579 次对话</li>
<li>617部电影中的9,035电影角色</li>
<li>总共304,713中语调</li>
</ul>
<p>这个数据集庞大而多样，在语言形式、时间段、情感上等都有很大的变化。我们希望这种多样性使我们的模型能够适应多种形式的输入和查询。</p>
<p>首先，把数据集下载并解压到Google云盘,在colab中挂在google云盘：</p>
<pre class=" language-py"><code class="language-py">from google.colab import drive
drive.mount('/content/drive')</code></pre>
<p>然后,我们通过数据文件的某些行来查看原始数据的格式</p>
<pre class=" language-py"><code class="language-py"># corpus_name = "cornell movie-dialogs corpus"
# corpus = os.path.join("data", corpus_name)
corpus = "/content/drive/My Drive/Colab Notebooks"
def preview(file,n=10):
  with open(file,'rb') as f:
    lines = f.readlines()
  for line in lines[:n]:
    print(line)
preview(os.path.join(corpus, "movie_lines.txt"))</code></pre>
<p>输出:</p>
<pre class=" language-py"><code class="language-py">b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n'
b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n'
b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n'
b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n'
b"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n"
b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n'
b"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n"
b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n'
b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\'m kidding.  You know how sometimes you just become this "persona"?  And you don\'t know how to quit?\n'
b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n'</code></pre>
<pre class=" language-py"><code class="language-py"># corpus_name = "cornell movie-dialogs corpus"
# corpus = os.path.join("data", corpus_name)
corpus = "/content/drive/My Drive/Colab Notebooks"
def preview(file,n=10):
  with open(file,'rb') as f:
    lines = f.readlines()
  for line in lines[:n]:
    print(line)
preview(os.path.join(corpus, "movie_conversations.txt"))</code></pre>
<p>输出：</p>
<pre class=" language-py"><code class="language-py">b"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n"
b"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n"
b"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n"
b"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n"
b"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n"
b"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n"
b"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n"
b"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n"
b"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\n"
b"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\n"</code></pre>
<h3 id="创建格式化数据文件"><a href="#创建格式化数据文件" class="headerlink" title="创建格式化数据文件"></a>创建格式化数据文件</h3><p>为了方便起见，我们将创建一个格式良好的数据文件，其中每一行包含一个由 <code>tab</code> 制表符分隔的查询语句和响应语句对。直接运行google提供的源码可能会出错，这里已经修补了一个小bug。</p>
<p>以下三个函数便于解析原始 movie_lines.txt 数据文件。</p>
<ul>
<li><code>loadLines</code> 将文件的每一行拆分为字段(lineID, characterID, movieID, character, text)组合的字典 </li>
<li><code>loadConversations</code> 根据 movie_conversations.txt 将 <code>loadLines</code> 中的每一行数据进行归类</li>
<li><code>extractSentencePairs</code> 从对话中提取一对句子</li>
</ul>
<pre class=" language-py"><code class="language-py"># fields = ["lineID", "characterID", "movieID", "character", "text"]
def loadLines(fileName, fields):
    lines = {}
    with open(fileName, 'r', encoding='iso-8859-1') as f:
        for line in f:
            values = line.split(" +++$+++ ")
            # Extract fields
            lineObj = {}
            for i, field in enumerate(fields):
                lineObj[field] = values[i]
            lines[lineObj['lineID']] = lineObj
    return lines
# 将文件的每一行拆分为字段字典
# line = {
#     'L183198': {
#         'lineID': 'L183198', 
#         'characterID': 'u5022', 
#         'movieID': 'm333', 
#         'character': 'FRANKIE', 
#         'text': "Well we'd sure like to help you.\n"
#     }, {...}
# }

# lines为loadLines()提取文本之后的字典, fields == ["character1ID", "character2ID", "movieID", "utteranceIDs"]
def loadConversations(fileName, lines, fields):
    conversations = []
    with open(fileName, 'r', encoding='iso-8859-1') as f:
        for line in f:
            values = line.split(" +++$+++ ")
            # Extract fields
            convObj = {}
            for i, field in enumerate(fields):
                convObj[field] = values[i]
            # Convert string to list (convObj["utteranceIDs"] == "['L598485', 'L598486', ...]")
            # eval() 函数用来执行一个字符串表达式，并返回表达式的值 x=7,eval('3*x')=21
            lineIds = eval(convObj["utteranceIDs"])
            # Reassemble lines
            # 多加了lines这一个key 把 utteranceIDs对应的 lines加载进来
            convObj["lines"] = []
            for lineId in lineIds:
              if lines.get(lineId) is not None:
                convObj["lines"].append(lines[lineId])nv
            conversations.append(convObj)
    return conversations
# 将 `loadLines` 中的行字段分组为基于 *movie_conversations.txt* 的对话
# [{
#     'character1ID': 'u0',
#     'character2ID': 'u2',
#     'movieID': 'm0',
#     'utteranceIDs': "['L194', 'L195', 'L196', 'L197']\n",
#     'lines': [{
#         'lineID': 'L194',
#         'characterID': 'u0',
#         'movieID': 'm0',
#         'character': 'BIANCA',
#         'text': 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n'
#     }, {
#         'lineID': 'L195',
#         'characterID': 'u2',
#         'movieID': 'm0',
#         'character': 'CAMERON',
#         'text': "Well, I thought we'd start with pronunciation, if that's okay with you.\n"
#     }, {
#         'lineID': 'L196',
#         'characterID': 'u0',
#         'movieID': 'm0',
#         'character': 'BIANCA',
#         'text': 'Not the hacking and gagging and spitting part.  Please.\n'
#     }, {
#         'lineID': 'L197',
#         'characterID': 'u2',
#         'movieID': 'm0',
#         'character': 'CAMERON',
#         'text': "Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n"
#     }]
# }, {...}]


# 从对话中提取一对句子
def extractSentencePairs(conversations):
    qa_pairs = []
    for conversation in conversations:
        # Iterate over all the lines of the conversation
        for i in range(len(conversation["lines"]) - 1):  # We ignore the last line (no answer for it)
            inputLine = conversation["lines"][i]["text"].strip()
            targetLine = conversation["lines"][i+1]["text"].strip()
            # Filter wrong samples (if one of the lists is empty)
            if inputLine and targetLine:
                qa_pairs.append([inputLine, targetLine])
    return qa_pairs
</code></pre>
<p>现在我们将调用这些函数来创建文件，我们命名为 <em>formatted_movie_lines.txt</em>.</p>
<pre class=" language-py"><code class="language-py"># Define path to new file
datafile = os.path.join(corpus, "formatted_movie_lines.txt")

delimiter = '\t'
# Unescape the delimiter
delimiter = str(codecs.decode(delimiter, "unicode_escape"))

# Initialize lines dict, conversations list, and field ids
lines = {}
conversations = []
MOVIE_LINES_FIELDS = ["lineID", "characterID", "movieID", "character", "text"]
MOVIE_CONVERSATIONS_FIELDS = ["character1ID", "character2ID", "movieID", "utteranceIDs"]

# Load lines and process conversations
print("\nProcessing corpus...")
lines = loadLines(os.path.join(corpus, "movie_lines.txt"), MOVIE_LINES_FIELDS)
print("\nLoading conversations...")
conversations = loadConversations(os.path.join(corpus, "movie_conversations.txt"),
                                  lines, MOVIE_CONVERSATIONS_FIELDS)

# Write new csv file
print("\nWriting newly formatted file...")
with open(datafile, 'w', encoding='utf-8') as outputfile:
    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\n')
    for pair in extractSentencePairs(conversations):
        writer.writerow(pair)

# Print a sample of lines
print("\nSample lines from file:")
preview(datafile)</code></pre>
<p>输出:</p>
<pre class=" language-py"><code class="language-py">Processing corpus...

Loading conversations...

Writing newly formatted file...

Sample lines from file:
b"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\tWell, I thought we'd start with pronunciation, if that's okay with you.\r\n"
b"Well, I thought we'd start with pronunciation, if that's okay with you.\tNot the hacking and gagging and spitting part.  Please.\r\n"
b"Not the hacking and gagging and spitting part.  Please.\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\r\n"
b"You're asking me out.  That's so cute. What's your name again?\tForget it.\r\n"
b"No, no, it's my fault -- we didn't have a proper introduction ---\tCameron.\r\n"
b"Cameron.\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\r\n"
b"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\tSeems like she could get a date easy enough...\r\n"
b'Why?\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\r\n'
b"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\tThat's a shame.\r\n"
b'Gosh, if only we could find Kat a boyfriend...\tLet me see what I can do.\r\n'
</code></pre>
<h3 id="加载和清洗数据"><a href="#加载和清洗数据" class="headerlink" title="加载和清洗数据"></a>加载和清洗数据</h3><p>我们下一个任务是创建词汇表并将查询/响应句子对（对话）加载到内存。</p>
<p>注意我们正在处理<strong>词序</strong>，这些词序没有映射到离散数值空间。因此，我们必须通过数据集中的单词来创建一个索引。</p>
<p>为此我们创建了一个<code>Voc</code>类,它会存储从单词到索引的映射、索引到单词的反向映射、每个单词的计数和总单词量。这个类提供向词汇表中添加单词的方法(<code>addWord</code>)、添加所有单词到句子中的方法 (<code>addSentence</code>) 和清洗不常见的单词方法(<code>trim</code>)。更多的数据清洗在后面进行。</p>
<pre class=" language-py"><code class="language-py"># Default word tokens
PAD_token = 0  # Used for padding short sentences
SOS_token = 1  # Start-of-sentence token
EOS_token = 2  # End-of-sentence token

class Voc:
    def __init__(self, name):
        self.name = name
        self.trimmed = False
        self.word2index = {}
        self.word2count = {}
        self.index2word = {PAD_token: "PAD", SOS_token: "SOS", EOS_token: "EOS"}
        self.num_words = 3  # Count SOS, EOS, PAD

    def addSentence(self, sentence):
        for word in sentence.split(' '):
            self.addWord(word)

    def addWord(self, word):
        if word not in self.word2index:
            self.word2index[word] = self.num_words
            self.word2count[word] = 1
            self.index2word[self.num_words] = word
            self.num_words += 1
        else:
            self.word2count[word] += 1

    # 删除低于特定计数阈值的单词
    def trim(self, min_count):
        if self.trimmed:
            return
        self.trimmed = True

        keep_words = []

        for k, v in self.word2count.items():
            if v >= min_count:
                keep_words.append(k)

        print('keep_words {} / {} = {:.4f}'.format(
            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)
        ))

        # Reinitialize dictionaries
        self.word2index = {}
        self.word2count = {}
        self.index2word = {PAD_token: "PAD", SOS_token: "SOS", EOS_token: "EOS"}
        self.num_words = 3 # Count default tokens

        for word in keep_words:
            self.addWord(word)
</code></pre>
<p>现在我们可以组装词汇表和查询/响应语句对。在使用数据之前，我们必须做一些预处理。</p>
<p>首先，我们必须使用<code>unicodeToAscii</code>将unicode字符串转换为ASCII。然后，我们应该将所有字母转换为小写字母并清洗掉除基本标点之外的所有非字母字符 (<code>normalizeString</code>)。最后，为了帮助训练收敛，我们将过滤掉长度大于<code>MAX_LENGTH</code> 的句子 (<code>filterPairs</code>)。</p>
<pre class=" language-py"><code class="language-py">MAX_LENGTH = 10  # Maximum sentence length to consider

# Turn a Unicode string to plain ASCII, thanks to
# https://stackoverflow.com/a/518232/2809427
def unicodeToAscii(s):
    return ''.join(
        c for c in unicodedata.normalize('NFD', s)
        if unicodedata.category(c) != 'Mn'
    )

# 初始化Voc对象 和 格式化pairs对话存放到list中
def readVocs(datafile, corpus_name):
    print("Reading lines...")
    # Read the file and split into lines
    lines = open(datafile, encoding='utf-8').read().strip().split('\n')
    # Split every line into pairs and normalize
    pairs = [[normalizeString(s) for s in l.split('\t')] for l in lines]
    voc = Voc(corpus_name)
    return voc, pairs

# 如果对 'p' 中的两个句子都低于 MAX_LENGTH 阈值，则返回True
def filterPair(p):
    # Input sequences need to preserve the last word for EOS token
    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH

# 过滤满足条件的 pairs 对话
def filterPairs(pairs):
    return [pair for pair in pairs if filterPair(pair)]

# 使用上面定义的函数，返回一个填充的voc对象和对列表
def loadPrepareData(corpus, datafile, save_dir):
    print("Start preparing training data ...")
    voc, pairs = readVocs(datafile, corpus)
    print("Read {!s} sentence pairs".format(len(pairs)))
    pairs = filterPairs(pairs)
    print("Trimmed to {!s} sentence pairs".format(len(pairs)))
    print("Counting words...")
    for pair in pairs:
        voc.addSentence(pair[0])
        voc.addSentence(pair[1])
    print("Counted words:", voc.num_words)
    return voc, pairs

# Load/Assemble voc and pairs
save_dir = os.path.join("data", "save")
voc, pairs = loadPrepareData(corpus, corpus, datafile, save_dir)
# Print some pairs to validate
print("\npairs:")
for pair in pairs[:10]:
    print(pair)
</code></pre>
<p>输出：</p>
<pre class=" language-py"><code class="language-py">Start preparing training data ...
Reading lines...
Read 221282 sentence pairs
Trimmed to 64271 sentence pairs
Counting words...
Counted words: 18008

pairs:
['there .', 'where ?']
['you have my word . as a gentleman', 'you re sweet .']
['hi .', 'looks like things worked out tonight huh ?']
['you know chastity ?', 'i believe we share an art instructor']
['have fun tonight ?', 'tons']
['well no . . .', 'then that s all you had to say .']
['then that s all you had to say .', 'but']
['but', 'you always been this selfish ?']
['do you listen to this crap ?', 'what crap ?']
['what good stuff ?', 'the real you .']
</code></pre>
<p>另一种有利于让训练更快收敛的策略是去除词汇表中很少使用的单词。减少特征空间也会降低模型学习目标函数的难度。我们通过以下两个步骤完成这个操作:</p>
<ol>
<li>使用 <code>voc.trim</code> 函数去除 <code>MIN_COUNT</code> 阈值以下单词 。</li>
<li>如果句子中包含词频过小的单词，那么整个句子也被过滤掉。</li>
</ol>
<pre class=" language-py"><code class="language-py">MIN_COUNT = 3    # Minimum word count threshold for trimming

def trimRareWords(voc, pairs, MIN_COUNT):
    # Trim words used under the MIN_COUNT from the voc
    voc.trim(MIN_COUNT)
    # Filter out pairs with trimmed words
    keep_pairs = []
    for pair in pairs:
        input_sentence = pair[0]
        output_sentence = pair[1]
        keep_input = True
        keep_output = True
        # Check input sentence
        for word in input_sentence.split(' '):
            if word not in voc.word2index:
                keep_input = False
                break
        # Check output sentence
        for word in output_sentence.split(' '):
            if word not in voc.word2index:
                keep_output = False
                break

        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence
        if keep_input and keep_output:
            keep_pairs.append(pair)

    print("Trimmed from {} pairs to {}, {:.4f} of total".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))
    return keep_pairs

# Trim voc and pairs
pairs = trimRareWords(voc, pairs, MIN_COUNT)
</code></pre>
<p>输出:</p>
<pre class=" language-py"><code class="language-py">keep_words 7823 / 18005 = 0.4345
Trimmed from 64271 pairs to 53165, 0.8272 of total
</code></pre>
<h2 id="为模型准备数据"><a href="#为模型准备数据" class="headerlink" title="为模型准备数据"></a>为模型准备数据</h2><p>尽管我们已经投入了大量精力来准备和清洗我们的数据变成一个很好的词汇对象和一系列的句子对，但我们的模型最终希望以numerical torch 张量作为输入。 可以在 <a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html" target="_blank" rel="noopener">seq2seq translation tutorial</a> 中找到为模型准备处理数据的一种方法。 在该教程中，我们使用batch size 大小为1，这意味着我们所要做的就是将句子对中的单词转换为词汇表中的相应索引，并将其提供给模型。</p>
<p>但是，如果你想要加速训练或者想要利用GPU并行计算能力，则需要使用小批量 <code>mini-batches</code> 来训练。</p>
<p>使用小批量 <code>mini-batches</code> 也意味着我们必须注意批量处理中句子长度的变化。 为了容纳同一批次中不同大小的句子，我们将使我们的批量输入张量大小 <em>(max_length，batch_size)</em>，其中短于 <em>max_length</em> 的句子在 <em>EOS_token</em> 之后进行零填充（zero padded）。</p>
<p><strong>如果我们简单地通过将单词转换为索引 <code>indicesFromSentence</code> 和零填充 <code>zero-pad</code> 将我们的英文句子转换为张量，我们的张量将具有大小 <code>(batch_size，max_length)</code>，并且索引第一维将在所有时间步骤中返回完整序列。 但是，我们需要沿着时间对我们批量数据进行索引并且包括批量数据中所有序列。 因此，我们将输入批处理大小转换为 <code>(max_length，batch_size)</code>，以便跨第一维的索引返回批处理中所有句子的时间步长。 我们在 <code>zeroPadding</code> 函数中隐式处理这个转置。</strong></p>
<p><img src="./img/maxlength_batchsize.jpg" alt="batches"></p>
<p><code>inputvar</code> 函数处理将句子转换为张量的过程，最终创建正确大小的零填充张量。它还返回批处理中每个序列的长度张量 <code>(tensor of lengths)</code>，长度张量稍后将传递给我们的解码器。</p>
<p><code>outputvar</code> 函数执行与 <code>inputvar</code> 类似的函数，但他不返回长度张量，而是返回二进制 <code>mask tensor</code> 和最大目标句子长度。二进制 <code>mask tensor</code> 的大小与输出目标张量的大小相同，但作为 <em>PAD_token</em> 的每个元素都是0而其他元素都是1。</p>
<p><code>batch2traindata</code> 只需要取一批句子对，并使用上述函数返回输入张量和目标张量。</p>
<pre class=" language-py"><code class="language-py">def indexesFromSentence(voc, sentence):
    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]

# zip 对数据进行合并了，相当于行列转置了
def zeroPadding(l, fillvalue=PAD_token):
    return list(itertools.zip_longest(*l, fillvalue=fillvalue))

# 记录 PAD_token的位置为0， 其他的为1
def binaryMatrix(l, value=PAD_token):
    m = []
    for i, seq in enumerate(l):
        m.append([])
        for token in seq:
            if token == PAD_token:
                m[i].append(0)
            else:
                m[i].append(1)
    return m

# 返回填充前（加入结束index EOS_token做标记）的长度 和 填充后的输入序列张量
def inputVar(l, voc):
    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]
    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])
    padList = zeroPadding(indexes_batch)
    padVar = torch.LongTensor(padList)
    return padVar, lengths

# 返回填充前（加入结束index EOS_token做标记）最长的一个长度 和 填充后的输入序列张量, 和 填充后的标记 mask
def outputVar(l, voc):
    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]
    max_target_len = max([len(indexes) for indexes in indexes_batch])
    padList = zeroPadding(indexes_batch)
    mask = binaryMatrix(padList)
    mask = torch.ByteTensor(mask)
    padVar = torch.LongTensor(padList)
    return padVar, mask, max_target_len

# Returns all items for a given batch of pairs
def batch2TrainData(voc, pair_batch):
    pair_batch.sort(key=lambda x: len(x[0].split(" ")), reverse=True)
    input_batch, output_batch = [], []
    for pair in pair_batch:
        input_batch.append(pair[0])
        output_batch.append(pair[1])
    inp, lengths = inputVar(input_batch, voc)
    output, mask, max_target_len = outputVar(output_batch, voc)
    return inp, lengths, output, mask, max_target_len

# Example for validation
small_batch_size = 5
batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])
input_variable, lengths, target_variable, mask, max_target_len = batches

print("input_variable:", input_variable)
print("lengths:", lengths)
print("target_variable:", target_variable)
print("mask:", mask)
print("max_target_len:", max_target_len)
</code></pre>
<p>输出：</p>
<pre class=" language-py"><code class="language-py">input_variable: tensor([[  33,   50, 1134,  274,   34],
        [  50,   92,   25,    4,    4],
        [  47,    7,  148,    2,    2],
        [   7,  278,  356,    0,    0],
        [ 118,    6,   40,    0,    0],
        [  40,    2,    2,    0,    0],
        [  47,    0,    0,    0,    0],
        [   6,    0,    0,    0,    0],
        [   2,    0,    0,    0,    0]])
lengths: tensor([9, 6, 6, 3, 3])
target_variable: tensor([[  25,   45,   27,  147,  145],
        [  74,  201,  132,  582,    6],
        [  25, 2009,  385,    7,    2],
        [  89,  115,  188,   44,    0],
        [7048,  180,   53,  188,    0],
        [ 350, 3524, 7558,   76,    0],
        [   4, 1295,    2,    6,    0],
        [   2,    4,    0,    2,    0],
        [   0,    2,    0,    0,    0]])
mask: tensor([[1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1],
        [1, 1, 1, 1, 0],
        [1, 1, 1, 1, 0],
        [1, 1, 1, 1, 0],
        [1, 1, 1, 1, 0],
        [1, 1, 0, 1, 0],
        [0, 1, 0, 0, 0]], dtype=torch.uint8)
max_target_len: 9</code></pre>
<h2 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h2><h3 id="Seq2Seq模型"><a href="#Seq2Seq模型" class="headerlink" title="Seq2Seq模型"></a>Seq2Seq模型</h3><p>我们聊天机器人的大脑是序列到序列（seq2seq）模型。 seq2seq模型的目标是将可变长度序列作为输入，并使用固定大小的模型将可变长度序列作为输出返回。</p>
<p><a href="https://arxiv.org/abs/1409.3215" target="_blank" rel="noopener">Sutskever et al.</a> 发现通过一起使用两个独立的RNN，我们可以完成这项任务。 第一个RNN充当<strong>编码器</strong>，其将可变长度输入序列编码为固定长度上下文向量。 理论上，该上下文向量（RNN的最终隐藏层）将包含关于输入到机器人的查询语句的语义信息。 第二个RNN是一个<strong>解码器</strong>，它接收输入文字和上下文矢量，并返回序列中下一句文字的概率和在下一次迭代中使用的隐藏状态。</p>
<p><img src="img/encoder_decoder.jpg" alt="model"></p>
<p>图片来源: <a href="https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/" target="_blank" rel="noopener">https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/</a></p>
<h3 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h3><p>编码器RNN每次迭代中输入一个语句输出一个token（例如，一个单词），同时在这时间内输出“输出”向量和“隐藏状态”向量。 然后将隐藏状态向量传递到下一步，并记录输出向量。 编码器将其在序列中的每一点处看到的上下文转换为高维空间中的一系列点，解码器将使用这些点为给定任务生成有意义的输出。</p>
<p>我们的编码器的核心是由  <a href="https://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="noopener">Cho et al.</a> 等人发明的多层门循环单元。 在2014年，我们将使用GRU的双向变体，这意味着基本上有两个独立的RNN：一个以正常的顺序输入输入序列，另一个以相反的顺序输入输入序列。 每个网络的输出在每个时间步骤求和。 使用双向GRU将为我们提供编码过去和未来上下文的优势。</p>
<p>双向RNN：</p>
<p><a href="https://pytorch.org/tutorials/_images/RNN-bidirectional.png" target="_blank" rel="noopener"><img src="img/gru_bidirection.jpg" alt="rnn_bidir"></a></p>
<p>图片来源: <a href="https://colah.github.io/posts/2015-09-NN-Types-FP/" target="_blank" rel="noopener">https://colah.github.io/posts/2015-09-NN-Types-FP/</a></p>
<p>注意:<code>embedding</code>层用于在任意大小的特征空间中对我们的单词索引进行编码。 对于我们的模型，此图层会将每个单词映射到大小为<em>hidden_size</em>的特征空间。 训练后，这些值会被编码成和他们相似的有意义词语。</p>
<p>最后，如果将填充的一批序列传递给RNN模块，我们必须分别使用<code>torch.nn.utils.rnn.pack_padded_sequence</code>和<code>torch.nn.utils.rnn.pad_packed_sequence</code>在RNN传递时分别进行填充和反填充。这两个函数的具体功能是为了防止LSTM或者GRU前向传播时吧加入在训练数据的padding考虑进去，理论上可以不用，但是为了提高效率最好还是用。</p>
<h3 id="回顾一下两个函数"><a href="#回顾一下两个函数" class="headerlink" title="回顾一下两个函数"></a>回顾一下两个函数</h3><hr>
<p><code>pack_padded_sequence</code> 有三个参数：(input,lengths,batch_first)。<code>input</code>是上一步加padding的数据，length是各个sequence的实际长度，batch_first是数据各个dimension按照<code>[batch_size,sequence_legnth,data_dim]</code>顺序排列。 One example:<br>一个<code>lengths=[7,5,2]</code>的 mini-batch <code>batch_x</code>为：</p>
<pre class=" language-py"><code class="language-py">batch_x
Out[2]: 
tensor([[1, 1, 1, 1, 1, 1, 1],
        [3, 3, 3, 3, 3, 0, 0],
        [6, 6, 0, 0, 0, 0, 0]])</code></pre>
<p>经过<code>torch.nn.utils.pack_padded_sequence</code>压缩后得到<code>batch_x_pack</code>：</p>
<pre class=" language-py"><code class="language-py">rnn_utils.pack_padded_sequence(batch_x, [7,5,2], batch_first=True)
Out[3]: PackedSequence(
data=tensor([1., 3., 6., 1., 3., 6., 1., 3., 1., 3., 1., 3., 1., 1.]),
batch_sizes=tensor([3, 3, 2, 2, 2, 1, 1]))</code></pre>
<p>分析可以发现，它的输出有两部分组成，分别是data和batch_sizes,第一部分为原来的数据按照time step重新排列，而padding的部分，直接空过了。batch_sizes则是每次实际读入的数据量，也就是说吗，LSTM把一个mini-batch sequence 又重新划分了很多小的batch,每个小batch为所有sequence在当前time step对应的值，如果某sequence在当前time step已经没有值了，那么，就不再读入填充的0，而是降低batch_size。batch_size相当于是对训练数据的重新划分。体会一下传入<code>DataLoader</code> 中 <code>collate_fn</code> 的精妙之处：</p>
<pre class=" language-py"><code class="language-py">def clollate_fn(data):
    data.sort(key=lambda x: len(x),reverse=True)
    data_length = [len(sq) for sq in data]
    data = rnn_utils.pad_sequence(data,batch_first=True,padding_value=0)
    return data.unsqueeze(-1), data_length
</code></pre>
<p>首先，排序的目的是为了方便获取每个time_step的batch,防止中间夹杂着<code>padding</code>.
在 <code>collate_fn</code> 函数中，我们还用到了<code>run.utils.pad_sequence</code>函数，它的作用就是填充0，如给定一个原始的<strong>排序</strong>后输入序列 data_x</p>
<pre><code>tensor([[1, 1, 1, 1, 1, 1, 1],
        [3, 3, 3, 3, 3],
        [6, 6]
        ...,
        ])</code></pre><p>输入到<code>rnn_utils.pad_sequence(data,batch_first=True,padding_value=0)</code>之后的输出为：</p>
<pre><code>tensor([[1, 1, 1, 1, 1, 1, 1],
        [3, 3, 3, 3, 3, 0, 0],
        [6, 6, 0, 0, 0, 0, 0]
        ...,
        ])</code></pre><p>一般来说，经过LSTM后的<code>out</code>和<code>batch_x_pack</code>的一样，都是分为两部分：<code>data</code>和<code>batch_sizes</code>。其中<code>out</code>的data shape由原来的 <code>input_size (data_dim)</code>变成了<code>hidden size</code>, <code>batch_size</code>的shape保持一致。One example:</p>
<pre class=" language-py"><code class="language-py">out.data.shape
Out[5]: torch.Size([14, 10])
batch_x_pack.data.shape
Out[6]: torch.Size([14, 1])
out.batch_sizes
Out[7]: tensor([3, 3, 2, 2, 2, 1, 1])
batch_x_pack.batch_sizes
Out[8]: tensor([3, 3, 2, 2, 2, 1, 1])</code></pre>
<p>将 <code>out</code>输入到 <code>pad_packed_sequence</code>执行的是<code>pack_padded_sequence</code>的逆操作：</p>
<pre class=" language-py"><code class="language-py">out, (h1, c1) = net(batch_x_pack, (h0, c0))
out_pad, out_len = rnn_utils.pad_packed_sequence(out, batch_first=True)
out_pad.shape
Out[2]: torch.Size([3, 7, 10])
out.data.shape
Out[3]: torch.Size([14, 10])
out_len
Out[4]: tensor([7, 5, 2])</code></pre>
<p>我们发现，经过这样的操作之后，得到的<code>out_pad</code>的shape为<code>[3,7,10]</code>,对比 <code>batch_x</code>的形状<code>[3,7,1]</code>，这说明一个minibatch中有三个句子，每个句子有7个time step, 每个 time_step 数据从输入的1维映射成了LSTM的10维。 out_len的shape为[7,5,2]。</p>
<hr>
<p><strong>计算图:</strong></p>
<blockquote>
<ol>
<li>将单词索引转换为词嵌入 embeddings。</li>
<li>为RNN模块打包填充批次序列。</li>
<li>通过GRU进行前向传播。</li>
<li>反填充。</li>
<li>对双向GRU输出求和。</li>
<li>返回输出和最终隐藏状态。</li>
</ol>
</blockquote>
<p><strong>输入:</strong></p>
<ul>
<li><code>input_seq</code>：一批输入句子; shape =（<em>max_length，batch_size</em>）</li>
<li><code>input_lengths</code>：一批次中每个句子对应的句子长度列表;shape=(<em>batch_size</em>)</li>
<li><code>hidden:</code>隐藏状态; shape =(<em>n_layers x num_directions，batch_size，hidden_size</em>)</li>
</ul>
<p><strong>输出:</strong></p>
<ul>
<li><code>outputs：</code> GRU最后一个隐藏层的输出特征（双向输出之和）; shape =（<em>max_length，batch_size，hidden_size</em>）</li>
<li><code>hidden：</code> GRU更新隐藏状态; shape =（<em>n_layers x num_directions，batch_size，hidden_size</em>）</li>
</ul>
<pre class=" language-py"><code class="language-py">class EncoderRNN(nn.Module):
    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):
        super(EncoderRNN, self).__init__()
        self.n_layers = n_layers
        self.hidden_size = hidden_size
        self.embedding = embedding

        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'
        #   because our input size is a word embedding with number of features == hidden_size
        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,
                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)

    def forward(self, input_seq, input_lengths, hidden=None):
        # Convert word indexes to embeddings
        embedded = self.embedding(input_seq)
        # Pack padded batch of sequences for RNN module
        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)
        # Forward pass through GRU
        outputs, hidden = self.gru(packed, hidden)
        # Unpack padding
        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)
        # Sum bidirectional GRU outputs
        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]
        # Return output and final hidden state
        return outputs, hidden
</code></pre>
<h3 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h3><p>解码器RNN以token-by-token的方式生成响应语句。 它使用编码器的上下文向量和内部隐藏状态来生成序列中的下一个单词。 它持续生成单词，直到输出是<em>EOS_token</em>，这个表示句子的结尾。 一个vanilla seq2seq解码器的常见问题是，如果我们只依赖于上下文向量来编码整个输入序列的含义，那么我们很可能会丢失信息。尤其是在处理长输入序列时，这极大地限制了我们的解码器的能力。</p>
<p>为了解决这个问题,<a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="noopener">Bahdanau et al.</a> 等人创建了一种“attention mechanism”，允许解码器关注输入序列的某些部分，而不是在每一步都使用完全固定的上下文。模型首先预测当前目标词的单个对齐位置Aliged Position $p_{t}$。 然后使用以源位置$p_{t}$为中心的窗口来计算上下文向量$c_{t}$，即窗口中源隐状态的加权平均值。 权重$\alpha_{t}$是从当前目标状态(current target state)$h_{t}$和窗口中的那些源状态$\bar{h}_{s}$中推断出来的。<br><img src="img/local_attention.png" alt="attn2"></p>
<p><a href="https://arxiv.org/abs/1508.04025" target="_blank" rel="noopener">Luong et al.</a> 通过创造“Global attention”，改善了<a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="noopener">Bahdanau et al.</a> 的基础工作。 关键的区别在于，对于“Global attention”，我们考虑所有编码器的隐藏状态，而不是Bahdanau等人的“Local attention”，它只考虑当前步中编码器的隐藏状态。 另一个区别在于，通过“Global attention”，我们仅使用当前步的解码器的隐藏状态来计算注意力权重（或者能量）。 Bahdanau等人的注意力计算需要知道前一步中解码器的状态。 此外，Luong等人提供各种方法来计算编码器输出和解码器输出之间的注意权重（能量），称之为“score functions”：</p>
<p><a href="https://pytorch.org/tutorials/_images/scores.png" target="_blank" rel="noopener"><img src="img/score_function.png" alt="scores"></a></p>
<p>其中 $h_t = 当前目标解码器状态$，$\bar{h}_s= 所有编码器状态$。</p>
<p>总体而言，Global attention机制可以通过下图进行总结。 请注意，我们将“Attention Layer”用一个名为 <code>Attn</code> 的 <code>nn.Module</code> 来单独实现。 该模块的输出是经过softmax标准化后权重张量的大小（<em>batch_size，1，max_length</em>）。</p>
<p><a href="https://pytorch.org/tutorials/_images/global_attn.png" target="_blank" rel="noopener"><img src="img/global_attention.png" alt="global_attn"></a></p>
<pre class=" language-py"><code class="language-py"># Luong attention layer
class Attn(torch.nn.Module):
    def __init__(self, method, hidden_size):
        super(Attn, self).__init__()
        self.method = method
        if self.method not in ['dot', 'general', 'concat']:
            raise ValueError(self.method, "is not an appropriate attention method.")
        self.hidden_size = hidden_size
        if self.method == 'general':
            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)
        elif self.method == 'concat':
            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)
            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))

    def dot_score(self, hidden, encoder_output):
        return torch.sum(hidden * encoder_output, dim=2)

    def general_score(self, hidden, encoder_output):
        energy = self.attn(encoder_output)
        return torch.sum(hidden * energy, dim=2)

    def concat_score(self, hidden, encoder_output):
        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()
        return torch.sum(self.v * energy, dim=2)

    def forward(self, hidden, encoder_outputs):
        # Calculate the attention weights (energies) based on the given method
        if self.method == 'general':
            attn_energies = self.general_score(hidden, encoder_outputs)
        elif self.method == 'concat':
            attn_energies = self.concat_score(hidden, encoder_outputs)
        elif self.method == 'dot':
            attn_energies = self.dot_score(hidden, encoder_outputs)

        # Transpose max_length and batch_size dimensions
        attn_energies = attn_energies.t()

        # Return the softmax normalized probability scores (with added dimension)
        return F.softmax(attn_energies, dim=1).unsqueeze(1)
</code></pre>
<p>注意到 有一个 <code>self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))</code>,这个函数可以理解为一个类型转换函数，将一个不可训练类型的Tensor转换成可以训练的类型parameter，所以在参数优化的时候还是可以进行优化的)。在<code>concat注意力机制</code>中，权值$v_{a}^{T}$是不断学习的所以要是parameter类型，不直接使用一个torch.nn.Linear()可能是因为学习的效果不好。</p>
<p>现在我们已经定义了注意力子模块，我们可以实现真实的解码器模型。 对于解码器，我们将每次手动进行一批次的输入。 这意味着我们的词嵌入张量和GRU输出都将具有相同大小（<em>1，batch_size，hidden_size</em>）。</p>
<p><strong>计算图:</strong></p>
<blockquote>
<ol>
<li>获取当前输入的词嵌入</li>
<li>通过单向GRU进行前向传播</li>
<li>通过2输出的当前GRU计算注意力权重</li>
<li>将注意力权重乘以编码器输出以获得新的“weighted sum”上下文向量</li>
<li>使用[Luong eq.5]连接加权上下文向量和GRU输出</li>
<li>使用[Luong eq.6]预测下一个单词（没有softmax）</li>
<li>返回输出和最终隐藏状态</li>
</ol>
</blockquote>
<p>[Luong eq.5]: Computation path goes from $h_{t}$ → $\alpha_{t}$ → $c_{t}$ → $\tilde{h}<em>{t}$. Specifically, given the target hidden state $h</em>{t}$ and the source-side context vector $c_{t}$, we employ a simple concatenation layer to combine the information from both vectors to produce an attentional hidden state as follows:<br>$$\boldsymbol{\tilde{h}}<em>{t}=tanh(\boldsymbol{W}</em>{c}[\boldsymbol{c}<em>{t};\boldsymbol{h}</em>{t}])$$</p>
<p>[Luong eq.6]: The attention vector $\bm{\tilde{h}}<em>{t}$ si then fed through the softmax layer to produce the predictvie distribution formulated as:<br>$$ p(y</em>{t}|y_{&lt; t},x)=softmax(\bm{W}<em>{s}\bm{\tilde{h}}</em>{t})$$</p>
<p><strong>输入:</strong></p>
<ul>
<li><code>input_step</code>：每一步输入序列批次（一个单词）; shape =（<em>1，batch_size</em>）</li>
<li><code>last_hidden</code>：GRU的最终隐藏层; shape =（<em>n_layers x num_directions，batch_size，hidden_size</em>）</li>
<li><code>encoder_outputs</code>：编码器模型的输出; shape =（<em>max_length，batch_size，hidden_size</em>）</li>
</ul>
<p><strong>输出:</strong></p>
<ul>
<li><code>output</code>: 一个softmax标准化后的张量， 代表了每个单词在解码序列中是下一个输出单词的概率; shape =（<em>batch_size，voc.num_words</em>）</li>
<li><code>hidden</code>: GRU的最终隐藏状态; shape =（<em>n_layers x num_directions，batch_size，hidden_size</em>）</li>
</ul>
<pre class=" language-py"><code class="language-py">class LuongAttnDecoderRNN(nn.Module):
    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):
        super(LuongAttnDecoderRNN, self).__init__()

        # Keep for reference
        self.attn_model = attn_model
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.n_layers = n_layers
        self.dropout = dropout

        # Define layers
        self.embedding = embedding
        self.embedding_dropout = nn.Dropout(dropout)
        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))
        self.concat = nn.Linear(hidden_size * 2, hidden_size)
        self.out = nn.Linear(hidden_size, output_size)

        self.attn = Attn(attn_model, hidden_size)

    def forward(self, input_step, last_hidden, encoder_outputs):
        # Note: we run this one step (word) at a time
        # Get embedding of current input word
        embedded = self.embedding(input_step)
        embedded = self.embedding_dropout(embedded)
        # Forward through unidirectional GRU
        rnn_output, hidden = self.gru(embedded, last_hidden)
        # Calculate attention weights from the current GRU output
        attn_weights = self.attn(rnn_output, encoder_outputs)
        # Multiply attention weights to encoder outputs to get new "weighted sum" context vector
        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))
        # Concatenate weighted context vector and GRU output using Luong eq. 5
        rnn_output = rnn_output.squeeze(0)
        context = context.squeeze(1)
        concat_input = torch.cat((rnn_output, context), 1)
        concat_output = torch.tanh(self.concat(concat_input))
        # Predict next word using Luong eq. 6
        output = self.out(concat_output)
        output = F.softmax(output, dim=1)
        # Return output and final hidden state
        return output, hidden
</code></pre>
<h2 id="定义训练步骤"><a href="#定义训练步骤" class="headerlink" title="定义训练步骤"></a>定义训练步骤</h2><h3 id="Masked-损失"><a href="#Masked-损失" class="headerlink" title="Masked 损失"></a>Masked 损失</h3><p>由于我们处理的是批量填充序列，因此在计算损失时我们不能简单地考虑张量的所有元素。 我们定义<code>maskNLLLoss</code>可以根据解码器的输出张量、描述目标张量填充的binary mask张量来计算损失。 该损失函数计算与mask tensor中的1对应的元素的平均负对数似然。</p>
<p><code>torch.gather(input, dim, index, out=None)-&gt;Tensor</code> 沿着某个轴，按照指定维度采集数据，对于3维数据，相当于进行如下操作：</p>
<pre class=" language-py"><code class="language-py">out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0
out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1
out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2</code></pre>
<p>One example:<br>outputs1的维度为<code>[batch_size,vocab_size]</code>,即每个词在词汇表中的（softmax之后）概率。</p>
<p>outputs1</p>
<pre class=" language-py"><code class="language-py">tensor([[ 0.2000,  0.1000,  0.7000],
        [ 0.3000,  0.6000,  0.1000],
        [ 0.4000,  0.5000,  0.1000]])</code></pre>
<p><code>torch.gather(outputs1,1,torch.LongTensor([[1],[1],[1]])</code>表示在第一维选取第二个元素。</p>
<pre class=" language-py"><code class="language-py">temp = torch.gather(outputs1,1,torch.LongTensor([[1],[1],[1]]))
print(temp)
tensor([[ 0.1000],
        [ 0.6000],
        [ 0.5000]])</code></pre>
<p><code>torch.masked_slect(input,mask,out=None)</code>表示根据<code>mask(ByteTensor)</code>选取对应位置的值，返回一维张量。One example,</p>
<pre class=" language-py"><code class="language-py">print(mask)
tensor([[ 0],
        [ 1],
        [ 1]], dtype=torch.uint8)</code></pre>
<pre class=" language-py"><code class="language-py">temp2=torch.masked_select(temp,mask)
print(temp2)
tensor([ 0.6000,  0.5000])</code></pre>
<pre class=" language-py"><code class="language-py">def maskNLLLoss(inp, target, mask):
    nTotal = mask.sum()
    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))
    loss = crossEntropy.masked_select(mask).mean()
    loss = loss.to(device)
    return loss, nTotal.item()
</code></pre>
<h3 id="单次训练迭代"><a href="#单次训练迭代" class="headerlink" title="单次训练迭代"></a>单次训练迭代</h3><p> <code>train</code> 函数包含单次训练迭代的算法（单批输入）。</p>
<p>我们将使用一些巧妙的技巧来帮助融合：</p>
<ul>
<li>第一个技巧是使用 <strong>teacher forcing</strong>。 这意味着在一些概率是由<code>teacher_forcing_ratio</code>设置，我们使用当前目标单词作为解码器的下一个输入，而不是使用解码器的当前推测。 该技巧充当解码器的 training wheels，有助于更有效的训练。 然而，<strong>teacher forcing</strong> 可能导致推导中的模型不稳定，因为解码器可能没有足够的机会在训练期间真正地制作自己的输出序列。 因此，我们必须注意我们如何设置<code>teacher_forcing_ratio</code>，同时不要被快速的收敛所迷惑。</li>
<li>我们实现的第二个技巧是<strong>梯度裁剪(gradient clipping)</strong>。 这是一种用于对抗“爆炸梯度（exploding gradient）”问题的常用技术。 本质上，通过将梯度剪切或阈值化到最大值，我们可以防止在损失函数中梯度以指数方式增长并发生溢出（NaN）或者越过梯度陡峭的悬崖。</li>
</ul>
<p><a href="https://pytorch.org/tutorials/_images/grad_clip.png" target="_blank" rel="noopener"><img src="img/gradient_clipping.jpg" alt="grad_clip"></a></p>
<p>图片来源: Goodfellow et al. <em>Deep Learning</em>. 2016. <a href="https://www.deeplearningbook.org/" target="_blank" rel="noopener">https://www.deeplearningbook.org/</a></p>
<p><strong>Sequence of Operations:</strong></p>
<p><strong>操作顺序:</strong></p>
<blockquote>
<ol>
<li>通过编码器前向计算整个批次输入。</li>
<li>将解码器输入初始化为SOS_token，将隐藏状态初始化为编码器的最终隐藏状态。</li>
<li>通过解码器一次一步地前向计算输入一批序列。</li>
<li>如果teacher forcing算法：将下一个解码器输入设置为当前目标; 否则：将下一个解码器输入设置为当前解码器输出。</li>
<li>计算并累积损失。</li>
<li>执行反向传播。</li>
<li>裁剪梯度。</li>
<li>更新编码器和解码器模型参数。</li>
</ol>
</blockquote>
<p>注意:</p>
<p>PyTorch的RNN模块（<code>RNN</code>，<code>LSTM</code>，<code>GRU</code>）可以像任何其他非重复层一样使用，只需将整个输入序列（或一批序列）传递给它们。 我们在<code>编码器</code>中使用<code>GRU</code>层就是这样的。 实际情况是，在计算中有一个迭代过程循环计算隐藏状态的每一步。 或者，你每次只运行一个模块。 在这种情况下，我们在训练过程中手动循环遍历序列就像我们必须为<code>解码器</code>模型做的那样。 只要你正确的维护这些模型的模块，就可以非常简单的实现顺序模型。</p>
<pre class=" language-py"><code class="language-py">def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,
          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):

    # Zero gradients
    encoder_optimizer.zero_grad()
    decoder_optimizer.zero_grad()

    # Set device options
    input_variable = input_variable.to(device)
    lengths = lengths.to(device)
    target_variable = target_variable.to(device)
    mask = mask.to(device)

    # Initialize variables
    loss = 0
    print_losses = []
    n_totals = 0

    # Forward pass through encoder
    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)

    # Create initial decoder input (start with SOS tokens for each sentence)
    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])
    decoder_input = decoder_input.to(device)

    # Set initial decoder hidden state to the encoder's final hidden state
    decoder_hidden = encoder_hidden[:decoder.n_layers]

    # Determine if we are using teacher forcing this iteration
    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False

    # Forward batch of sequences through decoder one time step at a time
    if use_teacher_forcing:
        for t in range(max_target_len):
            decoder_output, decoder_hidden = decoder(
                decoder_input, decoder_hidden, encoder_outputs
            )
            # Teacher forcing: next input is current target
            decoder_input = target_variable[t].view(1, -1)
            # Calculate and accumulate loss
            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])
            loss += mask_loss
            print_losses.append(mask_loss.item() * nTotal)
            n_totals += nTotal
    else:
        for t in range(max_target_len):
            decoder_output, decoder_hidden = decoder(
                decoder_input, decoder_hidden, encoder_outputs
            )
            # No teacher forcing: next input is decoder's own current output
            _, topi = decoder_output.topk(1)
            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])
            decoder_input = decoder_input.to(device)
            # Calculate and accumulate loss
            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])
            loss += mask_loss
            print_losses.append(mask_loss.item() * nTotal)
            n_totals += nTotal

    # Perform backpropatation
    loss.backward()

    # Clip gradients: gradients are modified in place
    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)
    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)

    # Adjust model weights
    encoder_optimizer.step()
    decoder_optimizer.step()

    return sum(print_losses) / n_totals
</code></pre>
<h3 id="训练迭代"><a href="#训练迭代" class="headerlink" title="训练迭代"></a>训练迭代</h3><p>现在终于将完整的训练步骤与数据结合在一起了。 给定传递的模型，优化器，数据等，<code>trainIters</code>函数负责运行<code>n_iterations</code>的训练。这个功能不言自明，因为我们通过<code>train</code>函数的完成了繁重工作。</p>
<p>需要注意的一点是，当我们保存模型时，我们会保存一个包含编码器和解码器<code>state_dicts</code>（参数）、优化器的state_dicts、损失、迭代等的压缩包。以这种方式保存模型将为我们checkpoint,提供最大的灵活性。 加载checkpoint后，我们将能够使用模型参数进行推理，或者我们可以在我们中断的地方继续训练。</p>
<pre class=" language-py"><code class="language-py">def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):

    # Load batches for each iteration
    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])
                      for _ in range(n_iteration)]

    # Initializations
    print('Initializing ...')
    start_iteration = 1
    print_loss = 0
    if loadFilename:
        start_iteration = checkpoint['iteration'] + 1

    # Training loop
    print("Training...")
    for iteration in range(start_iteration, n_iteration + 1):
        training_batch = training_batches[iteration - 1]
        # Extract fields from batch
        input_variable, lengths, target_variable, mask, max_target_len = training_batch

        # Run a training iteration with batch
        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,
                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)
        print_loss += loss

        # Print progress
        if iteration % print_every == 0:
            print_loss_avg = print_loss / print_every
            print("Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}".format(iteration, iteration / n_iteration * 100, print_loss_avg))
            print_loss = 0

        # Save checkpoint
        if (iteration % save_every == 0):
            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))
            if not os.path.exists(directory):
                os.makedirs(directory)
            torch.save({
                'iteration': iteration,
                'en': encoder.state_dict(),
                'de': decoder.state_dict(),
                'en_opt': encoder_optimizer.state_dict(),
                'de_opt': decoder_optimizer.state_dict(),
                'loss': loss,
                'voc_dict': voc.__dict__,
                'embedding': embedding.state_dict()
            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))
</code></pre>
<h2 id="评估定义"><a href="#评估定义" class="headerlink" title="评估定义"></a>评估定义</h2><p>在训练模型后，我们希望能够自己与机器人交谈。 首先，我们必须定义我们希望模型如何解码编码输入。</p>
<h3 id="贪婪解码"><a href="#贪婪解码" class="headerlink" title="贪婪解码"></a>贪婪解码</h3><p>贪婪解码是我们在不使用 teacher forcing时在训练期间使用的解码方法。 换句话说，对于每一步，我们只需从具有最高softmax值的<code>decoder_output</code>中选择单词。 该解码方法在单步长级别上是最佳的。</p>
<p>为了便于贪婪解码操作，我们定义了一个<code>GreedySearchDecoder</code>类。 当运行时，类的实例化对象输入序列（<code>input_seq</code>）的大小是（<em>input_seq length，1</em>），标量输入（<code>input_length</code>）长度的张量和<code>max_length</code>来约束响应句子长度。 使用以下计算图来评估输入句子：</p>
<p><strong>计算图:</strong></p>
<blockquote>
<ol>
<li>通过编码器模型前向计算。</li>
<li>准备编码器的最终隐藏层，作为解码器的第一个隐藏输入。</li>
<li>将解码器的第一个输入初始化为SOS_token。</li>
<li>将初始化张量追加到解码后的单词中。</li>
<li>一次迭代解码一个单词token：  <ol>
<li>通过解码器进行前向计算。</li>
<li>获得最可能的单词token及其softmax分数。</li>
<li>记录token和分数。</li>
<li>准备当前token作为下一个解码器的输入。</li>
</ol>
</li>
<li>返回收集到的单词 tokens 和 分数。</li>
</ol>
</blockquote>
<pre class=" language-py"><code class="language-py">class GreedySearchDecoder(nn.Module):
    def __init__(self, encoder, decoder):
        super(GreedySearchDecoder, self).__init__()
        self.encoder = encoder
        self.decoder = decoder

    def forward(self, input_seq, input_length, max_length):
        # Forward input through encoder model
        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)
        # Prepare encoder's final hidden layer to be first hidden input to the decoder
        decoder_hidden = encoder_hidden[:decoder.n_layers]
        # Initialize decoder input with SOS_token
        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token
        # Initialize tensors to append decoded words to
        all_tokens = torch.zeros([0], device=device, dtype=torch.long)
        all_scores = torch.zeros([0], device=device)
        # Iteratively decode one word token at a time
        for _ in range(max_length):
            # Forward pass through decoder
            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)
            # Obtain most likely word token and its softmax score
            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)
            # Record token and score
            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)
            all_scores = torch.cat((all_scores, decoder_scores), dim=0)
            # Prepare current token to be next decoder input (add a dimension)
            decoder_input = torch.unsqueeze(decoder_input, 0)
        # Return collections of word tokens and scores
        return all_tokens, all_scores
</code></pre>
<h3 id="评估我们的文本"><a href="#评估我们的文本" class="headerlink" title="评估我们的文本"></a>评估我们的文本</h3><p>现在我们已经定义了解码方法，我们可以编写用于评估字符串输入句子的函数。 <code>evaluate</code>函数管理输入句子的低层级处理过程。我们首先使用batch_size == 1将句子格式化为输入批量的单词索引。我们通过将句子的单词转换为相应的索引，并通过转换维度来为我们的模型准备张量。我们还创建了一个 <code>lengths</code> 张量，其中包含输入句子的长度。在这种情况下，<code>lengths</code> 是标量因为我们一次只评估一个句子（batch_size == 1）。接下来，我们使用我们的<code>GreedySearchDecoder</code>实例化后的对象（<code>searcher</code>）获得解码响应句子的张量。最后，我们将响应的索引转换为单词并返回已解码单词的列表。</p>
<p><code>evaluateInput</code>充当聊天机器人的用户接口。调用时，将生成一个输入文本字段，我们可以在其中输入查询语句。在输入我们的输入句子并按Enter后，我们的文本以与训练数据相同的方式标准化，并最终被输入到评估函数以获得解码的输出句子。我们循环这个过程，这样我们可以继续与我们的机器人聊天直到我们输入“q”或“quit”。</p>
<p>最后，如果输入的句子包含一个不在词汇表中的单词，我们会通过打印错误消息并提示用户输入另一个句子来优雅地处理。</p>
<pre class=" language-py"><code class="language-py">def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):
    ### Format input sentence as a batch
    # words -> indexes
    indexes_batch = [indexesFromSentence(voc, sentence)]
    # Create lengths tensor
    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])
    # Transpose dimensions of batch to match models' expectations
    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)
    # Use appropriate device
    input_batch = input_batch.to(device)
    lengths = lengths.to(device)
    # Decode sentence with searcher
    tokens, scores = searcher(input_batch, lengths, max_length)
    # indexes -> words
    decoded_words = [voc.index2word[token.item()] for token in tokens]
    return decoded_words

def evaluateInput(encoder, decoder, searcher, voc):
    input_sentence = ''
    while(1):
        try:
            # Get input sentence
            input_sentence = input('> ')
            # Check if it is quit case
            if input_sentence == 'q' or input_sentence == 'quit': break
            # Normalize sentence
            input_sentence = normalizeString(input_sentence)
            # Evaluate sentence
            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)
            # Format and print response sentence
            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]
            print('Bot:', ' '.join(output_words))

        except KeyError:
            print("Error: Encountered unknown word.")
</code></pre>
<h2 id="运行模型"><a href="#运行模型" class="headerlink" title="运行模型"></a>运行模型</h2><p>最后，是时候运行我们的模型了！</p>
<p>无论我们是否想要训练或测试聊天机器人模型，我们都必须初始化各个编码器和解码器模型。 在接下来的部分中，我们设置所需要的配置，选择从头开始或设置检查点以从中加载，并构建和初始化模型。 您可以随意使用不同的配置来优化性能。</p>
<pre class=" language-py"><code class="language-py"># Configure models
model_name = 'cb_model'
attn_model = 'dot'
#attn_model = 'general'
#attn_model = 'concat'
hidden_size = 500
encoder_n_layers = 2
decoder_n_layers = 2
dropout = 0.1
batch_size = 64

# Set checkpoint to load from; set to None if starting from scratch
loadFilename = None
checkpoint_iter = 4000
#loadFilename = os.path.join(save_dir, model_name, corpus_name,
#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),
#                            '{}_checkpoint.tar'.format(checkpoint_iter))

# Load model if a loadFilename is provided
if loadFilename:
    # If loading on same machine the model was trained on
    checkpoint = torch.load(loadFilename)
    # If loading a model trained on GPU to CPU
    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))
    encoder_sd = checkpoint['en']
    decoder_sd = checkpoint['de']
    encoder_optimizer_sd = checkpoint['en_opt']
    decoder_optimizer_sd = checkpoint['de_opt']
    embedding_sd = checkpoint['embedding']
    voc.__dict__ = checkpoint['voc_dict']

print('Building encoder and decoder ...')
# Initialize word embeddings
embedding = nn.Embedding(voc.num_words, hidden_size)
if loadFilename:
    embedding.load_state_dict(embedding_sd)
# Initialize encoder & decoder models
encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)
decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)
if loadFilename:
    encoder.load_state_dict(encoder_sd)
    decoder.load_state_dict(decoder_sd)
# Use appropriate device
encoder = encoder.to(device)
decoder = decoder.to(device)
print('Models built and ready to go!')
</code></pre>
<p>输出:</p>
<pre class=" language-py"><code class="language-py">Building encoder and decoder ...
Models built and ready to go!
</code></pre>
<h3 id="执行训练"><a href="#执行训练" class="headerlink" title="执行训练"></a>执行训练</h3><p>如果要训练模型，请运行以下部分。</p>
<p>首先我们设置训练参数，然后初始化我们的优化器，最后我们调用<code>trainIters</code>函数来运行我们的训练迭代。</p>
<pre class=" language-py"><code class="language-py"># Configure training/optimization
clip = 50.0
teacher_forcing_ratio = 1.0
learning_rate = 0.0001
decoder_learning_ratio = 5.0
n_iteration = 4000
print_every = 1
save_every = 500

# Ensure dropout layers are in train mode
encoder.train()
decoder.train()

# Initialize optimizers
print('Building optimizers ...')
encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)
decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)
if loadFilename:
    encoder_optimizer.load_state_dict(encoder_optimizer_sd)
    decoder_optimizer.load_state_dict(decoder_optimizer_sd)

# Run training iterations
print("Starting Training!")
trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,
           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,
           print_every, save_every, clip, corpus_name, loadFilename)
</code></pre>
<p>输出:</p>
<pre class=" language-py"><code class="language-py">Building optimizers ...
Starting Training!
Initializing ...
Training...
Iteration: 1; Percent complete: 0.0%; Average loss: 8.9717
Iteration: 2; Percent complete: 0.1%; Average loss: 8.8521
Iteration: 3; Percent complete: 0.1%; Average loss: 8.6360
Iteration: 4; Percent complete: 0.1%; Average loss: 8.4234
Iteration: 5; Percent complete: 0.1%; Average loss: 7.9403
Iteration: 6; Percent complete: 0.1%; Average loss: 7.3892
Iteration: 7; Percent complete: 0.2%; Average loss: 7.0589
Iteration: 8; Percent complete: 0.2%; Average loss: 7.0130
Iteration: 9; Percent complete: 0.2%; Average loss: 6.7383
Iteration: 10; Percent complete: 0.2%; Average loss: 6.5343
...
Iteration: 3991; Percent complete: 99.8%; Average loss: 2.6607
Iteration: 3992; Percent complete: 99.8%; Average loss: 2.6188
Iteration: 3993; Percent complete: 99.8%; Average loss: 2.8319
Iteration: 3994; Percent complete: 99.9%; Average loss: 2.5817
Iteration: 3995; Percent complete: 99.9%; Average loss: 2.4979
Iteration: 3996; Percent complete: 99.9%; Average loss: 2.7317
Iteration: 3997; Percent complete: 99.9%; Average loss: 2.5969
Iteration: 3998; Percent complete: 100.0%; Average loss: 2.2275
Iteration: 3999; Percent complete: 100.0%; Average loss: 2.7124
Iteration: 4000; Percent complete: 100.0%; Average loss: 2.5975
</code></pre>
<h3 id="运行评估"><a href="#运行评估" class="headerlink" title="运行评估"></a>运行评估</h3><p>To chat with your model, run the following block.<br>运行以下部分来与你的模型聊天</p>
<pre class=" language-py"><code class="language-py"># Set dropout layers to eval mode
encoder.eval()
decoder.eval()

# Initialize search module
searcher = GreedySearchDecoder(encoder, decoder)

# Begin chatting (uncomment and run the following line to begin)
# evaluateInput(encoder, decoder, searcher, voc)
</code></pre>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2>
            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">打个赏</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            <div class="reprint">
                <p>
                    <span class="reprint-tip">
                        <i class="fa fa-exclamation-circle"></i>&nbsp;&nbsp;转载规则:
                    </span>
                    <a href="https://zongdaoming.github.io" class="b-link-green">DorMin</a>
                    <i class="fa fa-angle-right fa-lg fa-fw text-color"></i>
                    <a href="/2019/09/09/machine-learning-base/multimodal-neural-translation/" class="b-link-green">multimodal neural translation tutorial</a>
                </p>
            </div>
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'cda4fee39cf105ea7637',
        clientSecret: '25ac3a74a67de2c6a82b5bbd65b4362273f4ed18',
        repo: 'zongdaoming.github.io',
        owner: 'zongdaoming',
        admin: "zongdaoming",
        id: '2019-09-09T15-23-19',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2019/09/12/3d-reconstruction/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/6.jpg" class="responsive-img" alt="3d_reconstruction">
                        
                        <span class="card-title">3d_reconstruction</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary"></div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2019-09-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Computer-Vision/" class="post-category" target="_blank">
                                    Computer Vision
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Machine-Learning/" target="_blank">
                        <span class="chip bg-color">Machine Learning</span>
                    </a>
                    
                    <a href="/tags/Computer-Vision/" target="_blank">
                        <span class="chip bg-color">Computer Vision</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2019/09/07/paper-writing/how-to-writing-paper/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/23.jpg" class="responsive-img" alt="How to write your first SCI paper?">
                        
                        <span class="card-title">How to write your first SCI paper?</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary">How to write your first SCI paper?这篇博客是清华大学刘洋老师在NLP会议上的报告PPT整理,原文机器翻译学术论文的写作方法和技巧. 写论文的本质是分享思想,呈现信息,虽然创新至上, 但是也需要掌握科学的写作</div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-09-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/paper-writing/" class="post-category" target="_blank">
                                    paper writing
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/writing-paper/" target="_blank">
                        <span class="chip bg-color">writing paper</span>
                    </a>
                    
                    <a href="/tags/logic-expression/" target="_blank">
                        <span class="chip bg-color">logic expression</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: DorMin<br />'
            + '作者: Zong Daoming<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>

    </div>
    <div class="col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
 MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
});
</script>

<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            本站由&copy;<a href="https://zongdaoming.github.io/" target="_blank">ZongDaoming</a>基于
            <a href="https://hexo.io/" target="_blank">Hexo</a> 的
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">hexo-theme-matery</a>主题搭建.

            
                &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
                <span class="white-color">37.8k</span>
            

            
			
                <br>
                
                <span id="busuanzi_container_site_pv">
                    <i class="fa fa-heart-o"></i>
                    本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
                </span>
                
                
                <span id="busuanzi_container_site_uv">
                    <i class="fa fa-users"></i>
                    次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
                </span>
                
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://zongdaoming.github.io" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:ecnuzdm@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1934703843" class="tooltipped" data-tooltip="QQ联系我: 1934703843" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>


<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


</body>
</html>