<!DOCTYPE HTML>
<html lang="zh-CN">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="multimodal neural translation series 2, DorMin">
    <meta name="description" content="
作者: [Thang Luong, Eugene Brevdo, Rui Zhao] (Google Research Blogpost, Github)


译者: 宗道明If make use of this codebase for">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>multimodal neural translation series 2 | DorMin</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>

<header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">DorMin</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>友情链接</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">DorMin</div>
        <div class="logo-desc">
            
            无名逆流
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                友情链接
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/zongdaoming/zongdaoming.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/zongdaoming/zongdaoming.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>





<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/13.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        multimodal neural translation series 2
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }
</style>
<div class="row">
    <div class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/ML/" target="_blank">
                                <span class="chip bg-color">ML</span>
                            </a>
                        
                            <a href="/tags/multimodal-translation/" target="_blank">
                                <span class="chip bg-color">multimodal translation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/ML/" class="post-category" target="_blank">
                                ML
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-09-15
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                        8.3k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        34 分
                    </div>
                    
                
				
				
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p><strong>作者</strong>: [Thang Luong, Eugene Brevdo, Rui Zhao] (<a href="https://research.googleblog.com/2017/07/building-your-own-neural-machine.html" target="_blank" rel="noopener">Google Research Blogpost</a>, <a href="https://github.com/tensorflow/nmt" target="_blank" rel="noopener">Github</a>)</p>
</blockquote>
<blockquote>
<p>译者: <a href="https://github.com/zongdaoming" target="_blank" rel="noopener">宗道明</a><br><em>If make use of this codebase for your research, please cite <a href="#bibtex">this</a>.</em></p>
</blockquote>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><hr>
<p>为了更深入地了解神经机器翻译和seq2seq模型，我们推荐以下材料:<a href="https://sites.google.com/site/acl16nmt/" target="_blank" rel="noopener">Luong, Cho, Manning, (2016)</a>; <a href="https://github.com/lmthang/thesis" target="_blank" rel="noopener">Luong, (2016)</a>; and <a href="https://arxiv.org/abs/1703.01619" target="_blank" rel="noopener">Neubig, (2017)</a>.
有很多构建seq2seq模型的工具，所以我们选择每种语言中的一个: </p>
<ul>
<li>tf-seq2seq (<a href="https://github.com/google/seq2seq)*[TensorFlow]" target="_blank" rel="noopener">https://github.com/google/seq2seq)*[TensorFlow]</a>* </li>
<li>OpenNMT <a href="http://opennmt.net/" target="_blank" rel="noopener">http://opennmt.net/</a> *[Torch]*</li>
<li>OpenNMT-py <a href="https://github.com/OpenNMT/OpenNMT-py" target="_blank" rel="noopener">https://github.com/OpenNMT/OpenNMT-py</a> *[PyTorch]*</li>
</ul>
<p>Sequence-to-sequence (seq2seq) 模型在机器翻译、语音识别、文本摘要等领域取得了不小的成功。我们旨在构建一个competitive seq2seq模型。我们将从一下三个方面着手实施我们的模型</p>
<ol>
<li><p>使用最新的<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/seq2seq/python/ops" target="_blank" rel="noopener">解码器/注意力包装器</a>和 Tensorflow 1.2 data iterator</p>
</li>
<li><p>构建完整的seq2seq模型</p>
</li>
<li><p>提供技巧以建立最好的NMT模型和复现<a href="https://research.google.com/pubs/pub45610.html" target="_blank" rel="noopener">谷歌NMT (GNMT)系统</a>。</p>
</li>
</ol>
<p>我们认为，提供人们可以复现的基准非常重要。因此，我们提供了完整的实验结果，并以下公开可用数据集对我们的模型进行了预训练:</p>
<ol>
<li><p><em>samll-scale</em>: 由<a href="https://sites.google.com/site/iwsltevaluation2015/" target="_blank" rel="noopener">IWSLT Evaluation Campaign</a>提供的英语-越语平行TED演讲语料库(133K句子对)</p>
</li>
<li><p><em>large-scale</em>: 由<a href="(http://www.statmt.org/wmt16/translation-task.html)">WMT Evaluation Campaign</a>提供的德语-英语平行语料库(450万对句子)。</p>
</li>
</ol>
<p>我们首先建立了一些关于NMT的seq2seq模型的基本知识，解释如何建立和训练一个普通的NMT模型。第二部分将详细介绍建立具有注意机制的竞争性的NMT模型。然后，我们将讨论一些技巧和技巧，以构建尽可能好的NMT模型(在速度和翻译质量方面)，比如<code>TensorFlow最佳实践(批处理、分段)</code>、<code>双向RNNs</code>、<code>束搜索</code>，以及使用<code>GNMT注意力</code>扩展到多个gpu。</p>
<h1 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h1><h2 id="神经机器翻译的背景"><a href="#神经机器翻译的背景" class="headerlink" title="神经机器翻译的背景"></a>神经机器翻译的背景</h2><p>在过去，传统的基于短语(phrase-based)的翻译系统通过将源句分成多个块，然后逐句翻译来完成任务。这导致了翻译输出的不流畅，与我们人类的翻译方式不太一样。我们通读整篇文章，理解它的意思，然后再翻译出来。神经机器翻译(NMT)模仿了这一点!</p>
<p align="center">
<img width="80%" src="img/encdec.jpg">
<br>
Figure 1. <b>Encoder-decoder architecture</b> – example of a general approach for
NMT. An encoder converts a source sentence into a "meaning" vector which is
passed through a <i>decoder</i> to produce a translation.
</p>

<p>具体地说，NMT系统首先使用编码器读取源语句来构建一个“thought”向量，即表示句子含义的数字序列;然后，解码器处理句子向量以发出翻译，如图1所示。这通常称为编解码器体系结构。通过这种方式，NMT以传统的基于短语的方法解决了本地翻译问题:它可以捕获语言中的长期依赖关系(long-range dependicies)，例如性别协议;语法结构;如谷歌神经机器翻译系统所演示的那样，生成更流畅的翻译。</p>
<p><code>NMT模型</code>根据其确切的体系结构而有所不同。序列数据的自然选择是<code>循环神经网络(RNN)</code>，大多数NMT模型都使用这种网络。通常RNN用于编码器和解码器。然而，RNN模型在以下方面有所不同:(a)方向性——单向或双向;(b)深度-单层或多层;(c)类型——通常是一个普通的RNN，一个长短时记忆(LSTM)，或者一个门控递归单元(GRU)。</p>
<p>在本教程中，我们以一个单向的、使用LSTM作为递归单元的多层RNN为例。在图2中我们展示了这样一个模型。在这个例子中，我们建立了一个模型，将源句“I am a student ”翻译成目标句“”Je suis étudiant”。在较高的层次上，NMT模型由两个循环神经网络组成:编码器RNN只消耗输入源词，不做任何预测;另一方面，解码器在处理<code>目标句子</code>的同时预测下一个单词。</p>
<p align="center">
<img width="50%" src="img/seq2seq.jpg">
<br>
Figure 2. <b>Neural machine translation</b> – example of a deep recurrent
architecture proposed by for translating a source sentence "I am a student" into
a target sentence "Je suis étudiant". Here, "&lts&gt" marks the start of the
decoding process while "&lt/s&gt" tells the decoder to stop.
</p>
在训练之前，确保你安装了tensorflow并下载了源码：
```py
git clone https://github.com/tensorflow/nmt/
```

<h2 id="训练——如何建立我们的第一个NMT系统训练"><a href="#训练——如何建立我们的第一个NMT系统训练" class="headerlink" title="训练——如何建立我们的第一个NMT系统训练"></a>训练——如何建立我们的第一个NMT系统训练</h2><pre class=" language-py"><code class="language-py">
```让我们首先深入到用具体的代码片段构建NMT模型的核心，通过这些代码片段，我们将更详细地解释图2。这部分引用[**model.py**]().

对于训练，我们将向系统提供以下张量，这些张量格式如下:

-  **encoder_inputs** [max_encoder_time, batch_size]: source input words.
-  **decoder_inputs** [max_decoder_time, batch_size]: target input words.
-  **decoder_outputs** [max_decoder_time, batch_size]: target output words, these are decoder_inputs shifted to the left by one time step with an end-of-sentence tag appended on the right.

为了提高效率，我们一次训练多个句子(batch_size)。测试时略有不同，所以我们将在稍后讨论它。


## Embedding
考虑到单词的分类特性，模型必须首先查找源和目标嵌入(look up source and target embddings)，以检索相应的单词表示。要使这个嵌入层起作用，首先为每种语言选择一个词汇表。通常，选择词汇量为V的单词，只有最频繁的V单词才被视为惟一的。所有其他单词都转换为“unknown” token，并得到相同的嵌入。嵌入权重(每种语言一组)通常是在训练中学习的。
```py
embedding_encoder = variable_scope.get_variable("embedding_encoder",[src_vocab_size,embedding_size],...)
# Look up embedding:
# encoder_inputs: [max_time,batch_size]
# encoder_emb_inp:[max_time,batch_size,embedding_size]
encoder_emb_inp = embedding_ops.embedding_lookup(embedding_encoder,encoder_inputs)</code></pre>
<p>类似地，我们可以构建embedding_decoder和decoder_emb_inp。注意，可以选择使用预先训练的单词表示(如<code>word2vec</code>或<code>Glove向量</code>)初始化嵌入权重。通常，给定大量的训练数据，我们可以从头开始学习这些嵌入。</p>
<h2 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h2><p>一旦检索到单词embeddings，就将其作为输入输入到主网络中，主网络由两个多层RNNs组成——源语言的编码器和目标语言的解码器。这两个RNNs在原则上可以共享相同的权重;然而，在实践中，我们经常使用两个不同的RNN参数(当拟合大型训练数据集时，这样的模型做得更好)。编码器RNN以零向量作为起始状态(starting state)，构造如下:</p>
<pre class=" language-py"><code class="language-py"># Build RNN cell
encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)

# Run Dynamic RNN
#   encoder_outputs: [max_time, batch_size, num_units]
#   encoder_state: [batch_size, num_units]
encoder_outputs, encoder_state = tf.nn.dynamic_rnn(
    encoder_cell, encoder_emb_inp,
    sequence_length=source_sequence_length, time_major=True)# Build RNN cell
encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)

# Run Dynamic RNN
#   encoder_outputs: [max_time, batch_size, num_units]
#   encoder_state: [batch_size, num_units]
encoder_outputs, encoder_state = tf.nn.dynamic_rnn(
    encoder_cell, encoder_emb_inp,
    sequence_length=source_sequence_length, time_major=True)</code></pre>
<p>注意，句子有不同的长度，为了避免浪费计算，我们通过<code>source_sequence_length</code>告诉<code>dynamic_rnn</code>确切的源语句长度。因为我们的输入是<code>time major</code>，所以设置<code>time_major=True</code>。在这里，我们只构建了单层LSTM encoder_cell。我们将在后面的部分中描述如何构建多层LSTMs、添加dropout和使用注意力。</p>
<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p>解码器也需要访问源信息，实现这一点的一个简单方法是使用编码器的最后一个隐藏状态encoder_state初始化它。在图2中，我们将源单词“student”的隐藏状态传递给解码器端。</p>
<pre class=" language-py"><code class="language-py"># Build RNN Cell
decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)

# Helper
helper = tf.contrib.seq2seq.TrainingHelper(
  decoder_emb_inp, decoder_lengths, time_major= True
)
# Decoder
decoder = tf.contrib.seq2seq.BasicDecoder(
  decoder_cell,helper,encoder_state,
  output_layer = projection_layer
)
# Dynamic decoding
outputs, _  =  tf.contrib.seq2seq.dynamic_decode(decoder,...)
logits = outputs.rnn_output</code></pre>
<p>这里，这段代码的核心部分是<code>BasicDecoder对象decoder</code>，它接收<code>decoder_cell</code>(类似于encoder_cell)、一个<code>helper</code>和前面的<code>encoder_state</code>作为输入。通过分离decoders和helpers，我们可以重用不同的代码库，例如，TrainingHelper可以用<code>GreedyEmbeddingHelper</code>替换来进行贪婪解码。请参阅<strong>helper.py</strong>。</p>
<p>最后，我们还没有提到projection_layer，它是一个将最上面的隐藏状态转换为维度$V$的logit向量的权重矩阵(dense matrix)。</p>
<pre class=" language-py"><code class="language-py">projection_layer = layers_core.Dense(tgt_vocab_size,use_bias =False)</code></pre>
<h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p>根据上面的逻辑，我们现在可以计算我们的训练损失:</p>
<pre class=" language-py"><code class="language-py">crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(
    labels=decoder_outputs, logits=logits)
train_loss = tf.reduce_sum(crossent * target_weights) /batch_size</code></pre>
<p>这里，target_weights是一个与decoder_output大小相同的0 - 1(mask)矩阵。它用值0掩盖目标序列长度之外的填充位置。</p>
<p>Note:值得指出的是，我们将损失除以batch_size，因此我们的超参数对于batch_size是“invarant”。有些人将损失除以(batch_size * num_time_steps)，这样可以减少短句子中的错误。更微妙的是，我们的超参数(应用于前一种方法)不能用于后一种方法。例如，如果两种方法都使用学习1.0的SGD，那么后一种方法有效地使用1 / num_time_steps的学习速率要小得多。</p>
<h2 id="Gradient-computation-amp-optimization"><a href="#Gradient-computation-amp-optimization" class="headerlink" title="Gradient computation &amp; optimization"></a>Gradient computation &amp; optimization</h2><p>我们现在已经定义了NMT模型的正向传递。计算反向传播传递只需几行代码:</p>
<pre class=" language-py"><code class="language-py">params = tf.trainable_variables()
gradients = tf.gradients(train_loss,params)
clipped_gradients, _ = tf.clip_by_global_norm(gradients, max_gradient_norm)</code></pre>
<p>梯度裁剪是训练神经网络的重要步骤之一。这里，我们按global norm, max_gradient_norm通常设置为5或1之类的值。最后一步是选择优化器。Adam优化器是一种常见的选择。我们还选择了一个学习率。learning_rate can的值通常在0.0001到0.001之间;并且可以随着训练步数的而减少。</p>
<pre class=" language-py"><code class="language-py">optimizer = tf.train.Adamoptimizer(learning_rate)
update_step = optimizer.apply_gradients(zip(clipped_gradients,params))</code></pre>
<h1 id="训练一个NMT模型"><a href="#训练一个NMT模型" class="headerlink" title="训练一个NMT模型"></a>训练一个NMT模型</h1><p>我们将使用一个小型的并行TED演讲语料库(133K个训练示例)来进行这个练习。我们在这里使用的所有数据都可以在<a href="1">1</a>中找到。我们将使用tst2012作为开发集，tst2013作为测试集。</p>
<p>运行以下命令下载训练NMT模型的数据:</p>
<pre class=" language-py"><code class="language-py">nmt/scripts/download_iwslt15.sh /tmp/nmt_data</code></pre>
<p>开始训练：</p>
<pre class=" language-shell"><code class="language-shell">mkdir /tmp/nmt_model
python -m nmt.nmt \
    --src=vi --tgt=en \
    --vocab_prefix=/tmp/nmt_data/vocab  \
    --train_prefix=/tmp/nmt_data/train \
    --dev_prefix=/tmp/nmt_data/tst2012  \
    --test_prefix=/tmp/nmt_data/tst2013 \
    --out_dir=/tmp/nmt_model \
    --num_train_steps=12000 \
    --steps_per_stats=100 \
    --num_layers=2 \
    --num_units=128 \
    --dropout=0.2 \
    --metrics=bleu</code></pre>
<p>上面的命令训练了一个2层的LSTM seq2seq模型。隐藏层单元为128，训练的epoch为12轮。</p>
<pre class=" language-py"><code class="language-py"># First evaluation, global step 0
  eval dev: perplexity 17193.66
  eval test: perplexity 17193.27
# Start epoch 0, step 0, lr 1, Tue Apr 25 23:17:41 2017
  sample train data:
    src_reverse: </s> </s> Điều đó , dĩ nhiên , là câu chuyện trích ra từ học thuyết của Karl Marx .
    ref: That , of course , was the <unk> distilled from the theories of Karl Marx . </s> </s> </s>
  epoch 0 step 100 lr 1 step-time 0.89s wps 5.78K ppl 1568.62 bleu 0.00
  epoch 0 step 200 lr 1 step-time 0.94s wps 5.91K ppl 524.11 bleu 0.00
  epoch 0 step 300 lr 1 step-time 0.96s wps 5.80K ppl 340.05 bleu 0.00
  epoch 0 step 400 lr 1 step-time 1.02s wps 6.06K ppl 277.61 bleu 0.00
  epoch 0 step 500 lr 1 step-time 0.95s wps 5.89K ppl 205.85 bleu 0.00</code></pre>
<p>我们可以启动Tensorboard查看训练时模型的总结:</p>
<pre class=" language-py"><code class="language-py">tensorboard --port 22222 --logdir /tmp/nmt_model/</code></pre>
<h1 id="推理：如何得到产生翻译"><a href="#推理：如何得到产生翻译" class="headerlink" title="推理：如何得到产生翻译"></a>推理：如何得到产生翻译</h1><p>当您在训练NMT模型(以及一旦您训练了模型)时，您可以获得给定的未见源语句的翻译。这个过程叫做推理。训练和推理(测试)有明显的区别:在推理时，我们只能访问源句，即 <code>encoder_inputs</code>。执行解码的方法有很多。译码方法包括<code>贪婪解码</code>、<code>采样解码</code>和<code>波束解码</code>译码。在这里，我们将讨论<code>贪婪解码</code>策略。</p>
<p>这个想法很简单，我们在图3中进行了说明:</p>
<ul>
<li><p>我们仍然使用与训练期间相同的方法对源语句进行编码，以获得 <code>encoder_state</code>，并且这个<code>encoder_state</code>用于初始化<code>解码器</code>。</p>
</li>
<li><p><code>解码器</code>一收到起始符号“&lt; s &gt;”(在我们的代码中称为tgt_sos_id)，即开始解码(翻译)过程;&lt;/ s&gt;</p>
</li>
<li><p>&lt; s &gt;对于解码器端的每个时间步，我们都将RNN的输出作为一组logits。我们选择最有可能的单词，即与最大logit值关联的id作为发出的单词(这是“贪婪”行为)。例如，在图3中，单词“moi”在第一个解码步骤中具有最高的翻译概率。然后我们将这个单词作为输入输入到下一个时间步中。&lt;/ s &gt;</p>
</li>
<li><p>&lt; s &gt;这个过程一直持续到句末标记“&lt;/ s &gt;”作为输出符号生成(在我们的代码中称tgt_eos_id)。</p>
</li>
</ul>
<p align="center">
<img width="40%" src="img/greedy.jpg">
<br>
Figure 3. <b>Greedy decoding</b> – example of how a trained NMT model produces a
translation for a source sentence "Je suis étudiant" using greedy search.
</p>

<p>第三步是推理和训练的不同之处。推理并不总是输入正确的目标单词(teacher forcing)，而是使用模型预测的单词。下面是实现<code>贪心解码</code>的代码。它与训练解码器非常相似。</p>
<pre class=" language-py"><code class="language-py"># Helper
helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(
    embedding_decoder,
    tf.fill([batch_size], tgt_sos_id), tgt_eos_id)
# Decoder
decoder = tf.contrib.seq2seq.BasicDecoder(
  decoder_cell,helper,encoder_state,
  output_layer =  projection_layers
)
# Dynamic decoding
outputs, _ = tf.contrib.seq2seq.dynamic_decoder(
  decoder, maximum_iterations = maximum_iterations
  translations = outputs.sample_id
)</code></pre>
<p>tf.fill(dims,values,name=None): 创建一个维度为dims，值为value的tensor对象．该操作会创建一个维度为dims的tensor对象，并将其值设置为value，该tensor对象中的值类型和value一致</p>
<p>当value为0时，该方法等同于tf.zeros()<br>当value为1时，该方法等同于tf.ones()<br>参数:</p>
<ul>
<li>dims: 类型为int32的tensor对象，用于表示输出的维度(1-D, n-D)，通常为一个int32数- 组，如：<a href="https://nlp.stanford.edu/projects/nmt/" target="_blank" rel="noopener">1</a>, [2,3]等</li>
<li>value: 常量值(字符串，数字等)，该参数用于设置到最终返回的tensor对象值中</li>
<li>name: 当前操作别名(可选)<br>返回: </li>
<li>tensor对象，类型和value一致<pre class=" language-py"><code class="language-py">import tensorflow as tf
sess = tf.InteractiveSession()
dim = [2,3]
tf.fill(dim, 5)
# [[5 5 5]
#  [5 5 5]]
tf.fill(dim, 5.0)
# [[ 5.  5.  5.]
#  [ 5.  5.  5.]]
tf.fill(dim, "5.0")
# [['5.0' '5.0' '5.0']
#  ['5.0' '5.0' '5.0']]</code></pre>
在这里，我们使用greedembeddinghelper而不是traininghelper。由于我们事先不知道 <code>目标序列</code>的长度，所以我们使用最大迭代次数来限制翻译长度。一种启发式方法是解码长度最多是<code>源语句</code>的两倍。<pre class=" language-py"><code class="language-py">maximum_iteration =  tf.round(tf.reduce_max(source_length)*2)</code></pre>
</li>
</ul>
<p>在训练了一个模型之后，我们现在可以创建一个推理文件并翻译一些句子:</p>
<pre class=" language-shell"><code class="language-shell">cat > /tmp/my_infer_file.vi
# (copy and paste some sentences from /tmp/nmt_data/tst2013.vi)

python -m nmt.nmt \
    --out_dir=/tmp/nmt_model \
    --inference_input_file=/tmp/my_infer_file.vi \
    --inference_output_file=/tmp/nmt_model/output_infer

cat /tmp/nmt_model/output_infer # To view the inference as output</code></pre>
<p>注意，只要有训练检查点,上述命令也可以在模型仍在训练时运行。有关详细信息，请参见[<strong>inference.py</strong>]</p>
<h1 id="Intermediate"><a href="#Intermediate" class="headerlink" title="Intermediate"></a>Intermediate</h1><p>在经历了最基本的seq2seq模型之后，让我们更进一步!为了构建最先进的神经机器翻译系统，我们需要更多的“secret source”:注意力机制，它最初由Bahdanau等人在2015年提出，后来由Luong等人在2015年等人完善。注意机制的核心思想是通过在翻译过程中“注意”相关的源内容，在目标和源之间建立直接的捷径连接。注意力机制的一个很好的副产品是源句和目标句之间的一个易于可视化的对齐矩阵(如图4所示)。</p>
<p align="center">
<img width="40%" src="img/attention_vis.jpg">
<br>
Figure 4. <b>Attention visualization</b> – example of the alignments between source
and target sentences. Image is taken from (Bahdanau et al., 2015).
</p>


<p>在普通的seq2seq模型中，在开始解码过程时，我们将<strong>最后一个源状态</strong>从编码器传递给解码器。这对于中短句很有效;然而，对于长句，<strong>单一的固定大小的隐藏状态</strong>成为信息瓶颈。<strong>注意力机制没有丢弃源RNN中计算的所有隐藏状态</strong>，而是提供了一种方法，允许解码器查看它们(将它们视为<strong>源信息的动态内存</strong>)。通过这样做，注意机制可以提高长句的翻译。如今，注意力机制已经成为事实上的标准 defacto standard，并已成功地应用于许多其他任务(包括图像标题生成(caption generation)、语音识别(speech recognition)和文本摘要(text summarization))。</p>
<h1 id="注意力机制的背景"><a href="#注意力机制的背景" class="headerlink" title="注意力机制的背景"></a>注意力机制的背景</h1><p>我们现在描述<a href>Luong et al.</a>中提出的注意机制的一个实例，该实例已在多个最先进的系统中使用，包括<a href="http://opennmt.net/about/" target="_blank" rel="noopener">OpenNMT</a>等开源工具包和本教程中的 <code>TF seq2seq API</code>。我们还将提供与注意机制的其他变体的连接。</p>
<p align="center">
<img width="48%" src="img/attention_mechanism.jpg">
<br>
Figure 5. <b>Attention mechanism</b> – example of an attention-based NMT system
as described in (Luong et al., 2015) . We highlight in detail the first step of
the attention computation. For clarity, we don't show the embedding and
projection layers in Figure (2).
</p>


<p>如图5所示，注意计算发生在每个解码器的时间步长。它包括下列各阶段:</p>
<ul>
<li>将当前<code>目标隐状态</code>与所有<code>源状态</code>进行比较，以获得<code>注意力权重</code>(可以如图4所示)。</li>
</ul>
<p>$$\alpha_{t s}=\frac{\exp \left(\operatorname{score}\left(\boldsymbol{h}<em>{t}, \overline{\boldsymbol{h}}</em>{s}\right)\right)}{\sum_{s^{\prime}=1}^{S} \exp \left(\operatorname{score}\left(\boldsymbol{h}<em>{t}, \overline{\boldsymbol{h}}</em>{s^{\prime}}\right)\right)} \quad \quad \text { [Attention weights ] }$$</p>
<ul>
<li><p>根据<code>注意力权值</code>计算<code>上下文向量</code>作为<code>源状态的加权平均</code>。
$$\boldsymbol{c}<em>{t}=\sum</em>{s} \alpha_{t s} \overline{\boldsymbol{h}}_{s} \quad \quad \text{ [Context vector] }$$</p>
</li>
<li><p>结合上下文向量和当前目标隐藏状态，生成最终的注意力向量(注意力隐状态)<br>$$\boldsymbol{\tilde{h}}<em>{t}=\tanh(\boldsymbol{W}</em>{c}[\boldsymbol{c}<em>{t};\boldsymbol{h}</em>{t}]) \quad \quad \text{ [Attention vector ]}$$</p>
</li>
<li><p>将注意力向量作为输入(input feeding)输入到下一个时间步。</p>
</li>
</ul>
<p>这里，<code>score function</code>用于将<code>目标隐状态</code>$\boldsymbol{h}<em>t$与每个<code>源状态</code> $\overline{h}</em>{s}$进行比较，并将结果规范化为产生的注意权重(分布在源位置上)。<code>评分函数</code>有多种选择; 常用的<code>评分函数</code>包括式(4)中给出的乘法和加法形式。一旦计算完毕，注意力向量$\boldsymbol{\tilde{h}}<em>{t}$将用于推导softmax logit 和 loss。这类似于普通seq2seq模型顶层的目标隐状态。注意力机制还可以有其他的选择，注意力机制的各种实现可以在<a href>attention_wrapper.py</a>中找到。<br>$$<br>\operatorname{score}\left(\boldsymbol{h}</em>{t}, \overline{\boldsymbol{h}}<em>{s}\right)=\left{\begin{array}{ll}{\boldsymbol{h}</em>{t}^{\top} \boldsymbol{W} \overline{\boldsymbol{h}}<em>{s}} &amp; {\text { [Luong’s multiplicative style] }} \ {\boldsymbol{v}</em>{a}^{\top} \tanh \left(\boldsymbol{W}<em>{1} \boldsymbol{h}</em>{t}+\boldsymbol{W}<em>{2} \overline{\boldsymbol{h}}</em>{s}\right)} &amp; {[\text { Bahdanau’s additive style }]}\end{array}\right.<br>$$</p>
<h3 id="在注意机制中什么是重要的"><a href="#在注意机制中什么是重要的" class="headerlink" title="在注意机制中什么是重要的?"></a>在注意机制中什么是重要的?</h3><p>正如上面的等式所暗示的，注意力有许多不同的变体。这些变体取决于<code>评分函数</code>和<code>注意力函数</code>的形式，以及是否如(Bahdanau et al.， 2015)论文中最初建议的那样，在<code>评分函数</code>中使用之前的目标隐状态$h_{t-1}$而不是当前的目标隐状态$h_t$。根据经验，我们发现只有特定的选择才重要。第一，注意力的基本形式，需要目标和源之间的直接连接。其次，重要的是将注意力向量提供给下一个时间步骤，以便将过去的注意力决策告知网络(Luong et al.， 2015)。最后，评分函数的选择常常会导致不同的性能。更多信息请参见基准测试结果部分。</p>
<h2 id="Attention-Wrapper-API"><a href="#Attention-Wrapper-API" class="headerlink" title="Attention Wrapper API"></a>Attention Wrapper API</h2><p>在实现AttentionWrapper时，我们借用了(Weston et al., 2015)](<a href="https://arxiv.org/abs/1410.3916)中关于内存网络的工作中的一些术语。本教程中介绍的注意机制是只读内存[read-only" target="_blank" rel="noopener">https://arxiv.org/abs/1410.3916)中关于内存网络的工作中的一些术语。本教程中介绍的注意机制是只读内存[read-only</a> memory]()，而不是可读和可写内存。具体地说，源隐状态集(或它们的转换版本，例如Luong评分风格中的$W\overline{h}_s$或Bahdanau评分风格的$W_2\overline{h}_s$)被称为“内存”。在每个时间步中，我们使用当前目标隐状态作为“查询”<a href>query</a>来决定读取内存的哪些部分。通常，需要将“查询”与对应于各个内存槽的键<a href>key</a>进行比较。在上面介绍注意机制时，我们碰巧使用了一组源隐状态(或者它们的转换版本，例如Bahdanau评分风格中的$W_1h_t$)作为“键”。我们可以从这个记忆网络术语中得到启发，衍生出其他形式的注意力!</p>
<p>有了注意力包装器，用注意力扩展我们的普通seq2seq代码将变得非常简单。这部分引用了代码<a href>attention_model.py</a>. 首先，我们需要定义一个注意机制，例如，from (Luong et al.， 2015):</p>
<pre class=" language-py"><code class="language-py"># attention_states: [batch_size, max_time, num_units]
attention_states = tf.transpose(encoder_outputs, [1, 0, 2])

# Create an attention mechanism
attention_mechanism = tf.contrib.seq2seq.LuongAttention(
    num_units, attention_states,
    memory_sequence_length=source_sequence_length)</code></pre>
<p>在前面的编码器部分中，encoder_output是顶层的所有<code>源隐状态</code>的集合(encoder_outputs is the set of all source hidden states at the top layer)，其形状为<a href>max_time、batch_size、num_units</a>,因为我们使用dynamic_rnn，为了提高效率，将time_major设置为True。对于注意机制，我们需要确保传入的“内存”是批处理主内存，因此需要转置attention_states。我们将source_sequence_length传递给注意机制，以确保注意力权重得到适当的规范化(仅针对非填充位置)。</p>
<p>定义了注意里机制后，我们使用AttentionWrapper来包装解码单元:</p>
<pre class=" language-py"><code class="language-py">decoder_cell = tf.contrib.seq2seq.AttentionWrapper(
  decoder_cell,attention_mechanism,
  attention_layer_size = num_units
)</code></pre>
<p>剩下的代码几乎与解码器中的代码相同！</p>
<h1 id="动手-建立一个基于注意力的NMT模型"><a href="#动手-建立一个基于注意力的NMT模型" class="headerlink" title="动手-建立一个基于注意力的NMT模型"></a>动手-建立一个基于注意力的NMT模型</h1><p>为了提高注意力，我们需要使用luong、scaled_luong、bahdanau或normed_bahdanau中的一个作为训练期间注意力机制。。此外，我们需要为注意力模型创建一个新目录，因此我们不重用以前训练过的基本NMT模型。</p>
<p>运行以下命令开始训练:</p>
<pre class=" language-shell"><code class="language-shell">mkdir /tmp/nmt_attention_model
python -m nmt.nmt \ 
    -- attention = scaled_luong \ 
    -- src = vi --tgt = en \
    -- vocab_prefix = /tmp/nmt_data/vocab \
    -- train_prefix = /tmp/nmt_data/train \
    -- dev_prefix = /tmp/nmt_data/tst2012 \
    -- test_prefix = /tmp/nmt_data/tst2013 \
    -- out_dir = /tmp/nmt_attention_model \
    -- num_train_steps = 12000 \
    -- steps_per_stats = 100 \
    -- num_layers = 2 \
    -- num_units = 128 \
    -- dropout = 0.2 \
    -- metrics = bleu</code></pre>
<p>经过训练，我们可以使用与新的out_dir相同的推理命令进行推理:</p>
<pre class=" language-shell"><code class="language-shell">python -m nmt.nmt \
    --out_dir=/tmp/nmt_attention_model \
    --inference_input_file=/tmp/my_infer_file.vi \
    --inference_output_file=/tmp/nmt_attention_model/output_infer</code></pre>
<h1 id="Tips-amp-Tricks"><a href="#Tips-amp-Tricks" class="headerlink" title="Tips &amp; Tricks"></a>Tips &amp; Tricks</h1><h2 id="Building-Training-Eval-and-Inference-Graphs"><a href="#Building-Training-Eval-and-Inference-Graphs" class="headerlink" title="Building Training, Eval, and Inference Graphs"></a>Building Training, Eval, and Inference Graphs</h2><p>在Tensorflow中构建机器学习模型时，通常最好构建三张单独的图：</p>
<ul>
<li><p>训练图(Training Graph):</p>
<ul>
<li>Batches, buckets, and possibly subsamples input data from a set of<br>files/external inputs.</li>
<li>Includes the forward and backprop ops.</li>
<li>Constructs the optimizer, and adds the training op.</li>
</ul>
</li>
<li><p>评估图(Eval Graph):</p>
<ul>
<li>Batches and buckets input data from a set of files/external inputs.</li>
<li>Includes the training forward ops, and additional evaluation ops that<br>aren’t used for training.</li>
</ul>
</li>
<li><p>推理图(Inference Graph):</p>
<ul>
<li>May not batch input data.</li>
<li>Does not subsample or bucket input data.</li>
<li>Reads input data from placeholders (data can be fed directly to the graph<br>via <em>feed_dict</em> or from a C++ TensorFlow serving binary).</li>
<li>Includes a subset of the model forward ops, and possibly additional<br>special inputs/outputs for storing state between session.run calls.</li>
</ul>
</li>
</ul>
<p>构建单独的图有几个好处:</p>
<ul>
<li><p>推理图通常与其他两个图非常不同，因此单独构建它是有意义的。 评估图(Eval Graph)变得更简单了，因为它不再有所有额外的支持操作。</p>
</li>
<li><p>可以为每个图分别实现数据输入。 变量重用要简单得多。例如，在评估图中，不需要使用<code>reuse=True</code>重新打开变量作用域，因为训练模型已经创建了这些变量。因此，可以重用相同的代码，而不需要到处散布<code>resue=arguments</code>。</p>
</li>
<li><p>在分布式训练中，让单独的工作人员执行训练、计算和推理是很常见的。无论如何，它们都需要构建自己的图。因此，以这种方式构建系统为分布式训练做好了准备。</p>
</li>
<li><p>复杂性的主要来源是如何在一个机器设置中跨三个图共享变量。这可以通过为每个图使用单独的会话来解决。训练会话(training Session)定期保存检查点，评估会话(eval session)和推断会话(infer session)从检查点恢复参数。下面的示例显示了这两种方法之间的主要区别。</p>
</li>
</ul>
<h3 id="例子1：一个图（a-single-graph）中的三个模型-three-models-和共享一个会话-a-single-session"><a href="#例子1：一个图（a-single-graph）中的三个模型-three-models-和共享一个会话-a-single-session" class="headerlink" title="例子1：一个图（a single graph）中的三个模型(three models)和共享一个会话 (a single session)"></a>例子1：一个图（a single graph）中的三个模型(three models)和共享一个会话 (a single session)</h3><pre class=" language-py"><code class="language-py">with tf.variable_scope("root"): 
    train_inputs =  tf.placeholder()
    train_op, loss = BuildTrainModel(train_inputs)
    initializer = tf.global_variables_initiazlizer()
with tf.variable_scope("root",reuse=True):
    eval_inputs =  tf.placeholder()
    eval_loss = BuilderEvalModel(eval_inputs)
with tf.variable_scope("root",reuse=True):
    infer_inputs = tf.placeholder()
    inference_output = BuildInference()
sess = tf.Session()
sess.run(initializer)
for i in itertools.count():
   train_input_data = ...
   sess.run([loss,train_op],feed_dict={train_inputs:train_input_data})
   if i % EVAL_STEPS == 0: 
    while data_to_eval:
       eval_input_data = ...
       sess.run([eval_loss],feed_dict={eval_inputs:eval_input_data})
   if i % INFER_STEPS == 0:
       sess.run(inference_output, feed_dict ={infer_inputs: infer_input_data})
sess = tf.Session()
sess.run(initializer)
for i in itertools.count():
  train_input_data = ...
  sess.run([loss, train_op], feed_dict={train_inputs: train_input_data})

  if i % EVAL_STEPS == 0:
    while data_to_eval:
      eval_input_data = ...
      sess.run([eval_loss], feed_dict={eval_inputs: eval_input_data})

  if i % INFER_STEPS == 0:
    sess.run(inference_output, feed_dict={infer_inputs: infer_input_data})</code></pre>
<p>注意后一种方法是如何“准备”转换为分布式版本的。</p>
<p>新方法的另一个区别是，我们使用有状态迭代器对象，而不是在每个<code>session.run</code>调用中使用<code>feed</code>指令来提供数据（从而执行我们自己的批处理、<code>bucketing</code>和数据操作）。这些迭代器使输入管道在单机和分布式设置中都更加容易。我们将在下一节介绍新的输入数据管道（如tensorflow 1.2中介绍的）。</p>
<h3 id="例子2：三个图中的三个模型，三个会话共享相同的变量"><a href="#例子2：三个图中的三个模型，三个会话共享相同的变量" class="headerlink" title="例子2：三个图中的三个模型，三个会话共享相同的变量"></a>例子2：三个图中的三个模型，三个会话共享相同的变量</h3><pre class=" language-py"><code class="language-py">train_graph = tf.Graph()
eval_graph = tf.Graph()
infer_graph = tf.Graph()

with train_graph.as_default():
  train_iterator = ...
  train_model = BuildTrainModel(train_iterator)
  initializer = tf.global_variables_initializer()
with eval_graph.as_default():
  eval_iterator = ...
  eval_model = BuildEvalModel(eval_iterator)
with infer_graph.as_default():
  infer_iterator, infer_inputs = ...
  infer_model = BuildInferenceModel(infer_iterator)
checkpoints_path = "/tmp/model/checkpoints"

train_sess = tf.Session(graph = train_graph)
eval_sess = tf.Session(graph =  eval_graph)
infer_sess = tf.Session(graph = infer_graph)

train_sess.run(initializer)
train_sess.run(train_iterator.initializer)

for i in itertools.count():
  train_model.train(train_sess)
  if i % EVAL_STEPS == 0:
    checkpoint_path = train_model.saver.save(train_sess, checkpoints_path, global_step=i)
    eval_model.saver.restore(eval_sess, checkpoint_path)
    eval_sess.run(eval_iterator.initializer)
    while data_to_eval:
      eval_model.eval(eval_sess)
  if i % INFER_STEPS == 0:
    checkpoint_path = train_model.saver.save(train_sess, checkpoints_path, global_step=i)
    infer_model.saver.restore(infer_sess,checkpoint_path)
    infer_sess.run(infer_iterator.initializer, feed_dict={infer_inputs:infer_input_data})
    while data_to_infer:
      infer_model.infer(infer_sess)</code></pre>
<h1 id="Other-details-for-better-NMT-models"><a href="#Other-details-for-better-NMT-models" class="headerlink" title="Other details for better NMT models"></a>Other details for better NMT models</h1><h2 id="Bidirectional-RNNs"><a href="#Bidirectional-RNNs" class="headerlink" title="Bidirectional RNNs"></a>Bidirectional RNNs</h2><p>编码器端的双向性通常会提供更好的性能（随着使用更多层，速度会有所下降）。这里，我们给出了一个简单的例子，说明如何构建一个具有单个双向层的编码器：</p>
<pre class=" language-py"><code class="language-py"># Construct forward and backward cells
forward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)
backward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)

bi_outputs, encoder_state =  tf.nn.bidirectional_dynamic_rnn(
  forward_cell, backward_cell, encoder_emb_inp,
  sequence_length = source_sequence_length, time_major = True)
)
encoder_outputs =  tf.concat(bi_outputs,-1)</code></pre>
<p>变量encoder_outputs和encoder_state使用方法与之前章节的编码器使用方法相同。请注意，对于多个双向层，我们需要稍微操作编码器状态，有关详细信息，请参见<a href>model.py</a>。</p>
<h2 id="Beam-search"><a href="#Beam-search" class="headerlink" title="Beam search"></a>Beam search</h2><p><code>贪婪解码</code>可以提供相当合理的翻译质量，而<code>波束搜索解码</code>可以进一步提高性能。beam搜索的思想是，在我们翻译的时候，通过保留一小部分优秀的候选词，更好地探索所有可能翻译的搜索空间。束的大小称为束宽；最小光束宽（如尺寸10）通常就足够了。下面是一个如何进行波束搜索的示例：</p>
<h3 id="Data-Input-Pipeline"><a href="#Data-Input-Pipeline" class="headerlink" title="Data Input Pipeline"></a>Data Input Pipeline</h3><p>在TensorFlow 1.2之前，用户有两个选项可以将数据提供给TensorFlow training 和eval pipeline:</p>
<ul>
<li>在每个训练会话中直接通过feed_dict提供数据。</li>
<li>使用tf中的排队机制。训练(例如tf.train.batch)和tf.contrib.train。</li>
<li>使用来自更高级别框架(如tf.contrib)的帮助程序。学习或tf.contrib。slim(有效地使用了#2)。</li>
</ul>
<p>第一种方法对于不熟悉TensorFlow或需要进行外来输入修改(即)，这只能在Python中完成。第二和第三种方法更标准，但灵活性稍差; 它们还需要启动多个python线程(队列运行器)。此外，<code>如果使用不当，队列可能导致死锁或不透明的错误消息</code>。然而，队列比使用<code>feed_dict</code>效率高得多，并且是单机和分布式训练的标准。</p>
<p>从Tensorflow 1.2开始，有一个新的系统可用于将数据读入tensorflow模型：dataset迭代器，如tf.data模块中所示。数据迭代器是灵活的，易于推理和操作，并通过利用Tensorflow C++ 运行时提供效率和多线程。</p>
<p>可以从批处理数据张量、文件名或包含多个文件名的张量创建数据集。一些例子：</p>
<pre class=" language-py"><code class="language-py"># Training dataset consists of multiple files.
train_dataset = tf.data.TextLineDataset(train_files)

# Evaluation dataset uses a single file, but we may
# point to a different file for each evaluation round.
eval_file = tf.placeholder(tf.string, shape=())
eval_dataset = tf.data.TextLineDataset(eval_file)

# For inference, feed input data to the dataset directly via feed_dict.
infer_batch = tf.placeholder(tf.string, shape=(num_infer_examples,))
infer_dataset = tf.data.Dataset.from_tensor_slices(infer_batch)</code></pre>
<p>所有数据集都可以通过输入处理进行类似的处理。这包括读取和清理数据、bucketing（在训练和评估的情况下）、过滤和批处理。</p>
<p>例如，要将每个句子转换为字符串向量，我们使用数据集映射转换：</p>
<pre class=" language-py"><code class="language-py">dataset = dataset.map(lambda string: tf.string_split([string]).values)</code></pre>
<p>然后，我们可以将每个<code>句子向量</code>转换为包含<code>向量</code>及其<code>动态长度</code>的<code>元组</code>：</p>
<pre class=" language-py"><code class="language-py">dataset = dataset.map(lambda words: (words, tf.size(words))</code></pre>
<p>最后，我们可以对每个句子执行词汇查找。给定一个查找表对象表，此映射将第一个元组元素从<code>字符串向量</code>转换为<code>整数向量</code>。</p>
<pre class=" language-py"><code class="language-py">dataset = dataset.map(lambda words, size:(table.looktup(words),size))</code></pre>
<p>连接两个数据集也很容易。如果两个文件包含彼此的逐行翻译，并且每个文件都读入自己的数据集，则可以通过以下方式创建包含压缩行元组的新数据集：</p>
<pre class=" language-py"><code class="language-py">source_target_data = tf.data.Dateset.zip((source_dataset,target_dataset))</code></pre>
<p>句子的变长批处理非常简单。以下转换将批处理<code>source_target_data</code>数据集中的<code>batch_size</code>元素，并分别将<code>源向量</code>和<code>目标向量</code>填充到每个批中最长的<code>源向量</code>和<code>目标向量</code>的长度。</p>
<pre class=" language-py"><code class="language-py">batched_dataset = source_target_dataset.padded_batch(
        batch_size,
        padded_shapes=((tf.TensorShape([None]),  # source vectors of unknown size
                        tf.TensorShape([])),     # size(source)
                       (tf.TensorShape([None]),  # target vectors of unknown size
                        tf.TensorShape([]))),    # size(target)
        padding_values=((src_eos_id,  # source vectors padded on the right with src_eos_id
                         0),          # size(source) -- unused
                        (tgt_eos_id,  # target vectors padded on the right with tgt_eos_id
                         0)))         # size(target) -- unused</code></pre>
<p>从该数据集中发出的值将是嵌套元组，其张量的最左维度为size <code>batch_size</code>。结构如下：</p>
<ul>
<li>迭代器<code>[0][0]</code>具有批处理和填充的源语句矩阵。</li>
<li>迭代器<code>[0][1]</code>具有批处理的源大小向量。</li>
<li>迭代器<code>[1][0]</code>具有批处理和填充的目标句子矩阵。</li>
<li>迭代器<code>[1][1]</code>具有批处理的目标大小向量。</li>
</ul>
<p>最后，将大小相似的源语句批量放在一起也是可能的。有关详细信息和完整的实现，请参阅文件<a href>utils/iterator_utils.py</a>。</p>
<p>从数据集中读取数据需要三行代码:创建迭代器、获取其值并初始化它。</p>
<pre class=" language-py"><code class="language-py">batched_iterator = batched_dataset.make_initializable_iterator ()
((source, source_length)， (target, target_length)) = batched_iterator.get_next()</code></pre>
<pre class=" language-py"><code class="language-py"># At initialization time
session.run (batched_iterator.initializer feed_dict = {…})</code></pre>
<p>初始化迭代器之后，访问源或目标张量的每个session.run调用都将从底层数据集中请求下一个mini批处理。</p>
<h1 id="附录-Tensorflow使用技巧"><a href="#附录-Tensorflow使用技巧" class="headerlink" title="附录 Tensorflow使用技巧"></a>附录 Tensorflow使用技巧</h1><h3 id="How-to-build-the-data-Pipeline"><a href="#How-to-build-the-data-Pipeline" class="headerlink" title="How to build the data Pipeline"></a>How to build the data Pipeline</h3><ul>
<li>学习如何使用tf.data和最佳实践</li>
<li>建立一个有效的管道来加载图像并对其进行预处理</li>
<li>为文本构建一个有效的管道，包括如何构建词汇表(build a vocabulary)</li>
</ul>
<p>Tensorflow 入门手册中一般介绍的是采用 <code>feed_dict</code>方法，在<code>tf.Session.run()</code> 会话运行或 <code>tf.Tensor.eval()</code> 函数调用时，将数据加载进模型. 然而，还有另一种更加有效和更简单的方式，即，采用 <code>tf.data</code> API，只需几行代码即可实现高效的数据管道(pipelines).</p>
<p>在 <code>feed_dict</code> 管道中，GPU 存在等待时间，需要等 CPU 提供下一个 batch 的数据. 如图：</p>
<p><img src="img/feeddict.jpg" alt="feeddict"></p>
<p>Dataset API允许构建一个<code>异步的、高度优化的数据管道</code>，以防止GPU的数据匮乏。它从磁盘(图像或文本)加载数据，应用优化转换，创建批并将其发送到GPU。以前的数据管道让GPU等待CPU加载数据，导致性能问题。在tf.data管道中，可以异步地拉取下一个batches的数据，以最小化闲置时间，而且还可以并行化数据加载和预处理操作，进一步加速数据管道。</p>
<p><img src="img/tfdata.jpg" alt="tf.data"></p>
<h3 id="Tensorflwo中变量管理reuse参数使用"><a href="#Tensorflwo中变量管理reuse参数使用" class="headerlink" title="Tensorflwo中变量管理reuse参数使用"></a>Tensorflwo中变量管理reuse参数使用</h3><p>Tensorflow中两个用于变量管理的函数</p>
<ul>
<li>tf.get_variable() ：用于创建和获取变量的值</li>
<li>tf.variable_scope()：  用于生成上下文管理器，创建命名空间，命名空间可以嵌套<br>其中， tf.get_variable()既可以创建变量，也可以获取变量。控制创建还是获取的开关来自函数tf.variable.scope()中的参数 <code>reuse=True</code> or <code>reuse = Flase</code>。</li>
</ul>
<ol>
<li>设置 reuse = False时，函数 get_variable()表示创建变量<pre class=" language-py"><code class="language-py">with tf.variable_scope("foo", reuse = False):
v =  tf.get_variable("v",[1],initializer = tf.constant_initialzier(1.0))</code></pre>
在tf.variable_scope()函数中，设置reuse=False(默认reuse=None)时，在其命名空间”foo”中执行函数get_variable（）时，表示创建变量”v”，若在该命名空间中已经有了变量”v”，则在创建时会报错，如下面的例子:</li>
</ol>
<pre class=" language-py"><code class="language-py">import tensorflow as tf
with  tf.variable_scope("foo"):
    v = tf.get_variable(name="v",shape=[1],initializer=tf.constant_initializer(1.0))
    v1 = tf.get_variable(name="v",shape=[1],initializer=tf.constant_initializer(1.0))
ValueError: Variable foo/v already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:</code></pre>
<ol start="2">
<li>设置reuse = True 时，函数 get_variable() 表示获取变量<pre class=" language-py"><code class="language-py">import tensorflow as tf
with  tf.variable_scope("foo"):
 v = tf.get_variable(name="v",shape=[1],initializer=tf.constant_initializer(1.0))
with tf.variable_scope("foo",reuse=True):
 v_test = tf.get_variable("v",shape=[1])
print(v_test==v)
True</code></pre>
</li>
<li>在tf.variable_scope()函数中，设置reuse=True时，在其命名空间”foo”中执行函数get_variable()时，表示获取变量”v”。若在该命名空间中还没有该变量，则在获取时会报错，如下面的例子<pre class=" language-py"><code class="language-py">import tensorflow as tf
with tf.variable_scope("foo",reuse=True):
 v_test = tf.get_variable("v",shape=[1])
print(v_test)
ValueError: Variable foo/v does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?</code></pre>
</li>
</ol>
<h1 id="BibTex"><a href="#BibTex" class="headerlink" title="BibTex"></a>BibTex</h1><pre><code>@article{luong17,
  author  = {Minh{-}Thang Luong and Eugene Brevdo and Rui Zhao},
  title   = {Neural Machine Translation (seq2seq) Tutorial},
  journal = {https://github.com/tensorflow/nmt},
  year    = {2017},
}</code></pre>
            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">打个赏</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            <div class="reprint">
                <p>
                    <span class="reprint-tip">
                        <i class="fa fa-exclamation-circle"></i>&nbsp;&nbsp;转载规则:
                    </span>
                    <a href="https://zongdaoming.github.io" class="b-link-green">DorMin</a>
                    <i class="fa fa-angle-right fa-lg fa-fw text-color"></i>
                    <a href="/2019/09/15/machine-learning-base/multimodal-neural-translation-tutorial2/" class="b-link-green">multimodal neural translation series 2</a>
                </p>
            </div>
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'cda4fee39cf105ea7637',
        clientSecret: '25ac3a74a67de2c6a82b5bbd65b4362273f4ed18',
        repo: 'zongdaoming.github.io',
        owner: 'zongdaoming',
        admin: "zongdaoming",
        id: '2019-09-15T13-26-41',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2019/09/17/machine-learning-base/multi-gpu-tensorflow/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/17.jpg" class="responsive-img" alt="Tensorflow指南(1)">
                        
                        <span class="card-title">Tensorflow指南(1)</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary">变量我们使用 tf.Variable 类操作变量。tf.Variable 表示可通过对其运行操作来改变其值的张量。与 tf.Tensor 对象不同，tf.Variable 存在于单个 session.run 调用的上下文之外，变量只存在与一</div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2019-09-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Tensorflow/" class="post-category" target="_blank">
                                    Tensorflow
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Tensorflow/" target="_blank">
                        <span class="chip bg-color">Tensorflow</span>
                    </a>
                    
                    <a href="/tags/Tricks/" target="_blank">
                        <span class="chip bg-color">Tricks</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2019/09/12/tools/docker-usage/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="Docker Usage">
                        
                        <span class="card-title">Docker Usage</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary">Docker从入门到放弃

作者: 宗道明

请参阅Tensorflow官方文档和Docker官方文档获得详细信息。
启动 TensorFlow Docker 容器要启动配置 TensorFlow 的容器，请使用以下命令格式：
docker</div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-09-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/tools/" class="post-category" target="_blank">
                                    tools
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/tools/" target="_blank">
                        <span class="chip bg-color">tools</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: DorMin<br />'
            + '作者: Zong Daoming<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>

    </div>
    <div class="col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
 MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
});
</script>

<footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            本站由&copy;<a href="https://zongdaoming.github.io/" target="_blank">ZongDaoming</a>基于
            <a href="https://hexo.io/" target="_blank">Hexo</a> 的
            <a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">hexo-theme-matery</a>主题搭建.

            
                &nbsp;<i class="fa fa-area-chart"></i>&nbsp;站点总字数:&nbsp;
                <span class="white-color">35.6k</span>
            

            
			
                <br>
                
                <span id="busuanzi_container_site_pv">
                    <i class="fa fa-heart-o"></i>
                    本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
                </span>
                
                
                <span id="busuanzi_container_site_uv">
                    <i class="fa fa-users"></i>
                    次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
                </span>
                
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://zongdaoming.github.io" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>



    <a href="mailto:ecnuzdm@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1934703843" class="tooltipped" data-tooltip="QQ联系我: 1934703843" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>
</div>
    </div>
</footer>

<div class="progress-bar"></div>


<!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
<!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


<script src="/libs/materialize/materialize.min.js"></script>
<script src="/libs/masonry/masonry.pkgd.min.js"></script>
<script src="/libs/aos/aos.js"></script>
<script src="/libs/scrollprogress/scrollProgress.min.js"></script>
<script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
<script src="/js/matery.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->



    <script src="/libs/others/clicklove.js"></script>


    <script async src="/libs/others/busuanzi.pure.mini.js"></script>


</body>
</html>